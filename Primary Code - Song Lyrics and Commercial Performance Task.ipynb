{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7defc604",
   "metadata": {},
   "source": [
    "# NLP Project - Song Lyrics and Commercial Performance\n",
    "### Project Code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af6c05fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theobragstad/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "import math\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "import spacy\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbda569",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "088cd804",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None # Hide irrelevant warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60640218",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\") # Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08fb4bb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>track_album_id</th>\n",
       "      <th>track_album_name</th>\n",
       "      <th>track_album_release_date</th>\n",
       "      <th>playlist_name</th>\n",
       "      <th>playlist_id</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0017A6SJgTbfQVU2EtsPNo</td>\n",
       "      <td>Pangarap</td>\n",
       "      <td>Barbie's Cradle</td>\n",
       "      <td>Minsan pa Nang ako'y napalingon Hindi ko alam ...</td>\n",
       "      <td>41</td>\n",
       "      <td>1srJQ0njEQgd8w4XSqI4JQ</td>\n",
       "      <td>Trip</td>\n",
       "      <td>2001-01-01</td>\n",
       "      <td>Pinoy Classic Rock</td>\n",
       "      <td>37i9dQZF1DWYDQ8wBxd7xt</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.068</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.27900</td>\n",
       "      <td>0.011700</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>0.566</td>\n",
       "      <td>97.091</td>\n",
       "      <td>235440</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004s3t0ONYlzxII9PLgU6z</td>\n",
       "      <td>I Feel Alive</td>\n",
       "      <td>Steady Rollin</td>\n",
       "      <td>The trees, are singing in the wind The sky blu...</td>\n",
       "      <td>28</td>\n",
       "      <td>3z04Lb9Dsilqw68SHt6jLB</td>\n",
       "      <td>Love &amp; Loss</td>\n",
       "      <td>2017-11-21</td>\n",
       "      <td>Hard Rock Workout</td>\n",
       "      <td>3YouF0u7waJnolytf9JCXf</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.739</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.01170</td>\n",
       "      <td>0.009940</td>\n",
       "      <td>0.3470</td>\n",
       "      <td>0.404</td>\n",
       "      <td>135.225</td>\n",
       "      <td>373512</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00chLpzhgVjxs1zKC9UScL</td>\n",
       "      <td>Poison</td>\n",
       "      <td>Bell Biv DeVoe</td>\n",
       "      <td>NA Yeah, Spyderman and Freeze in full effect U...</td>\n",
       "      <td>0</td>\n",
       "      <td>6oZ6brjB8x3GoeSYdwJdPc</td>\n",
       "      <td>Gold</td>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>Back in the day - R&amp;B, New Jack Swing, Swingbe...</td>\n",
       "      <td>3a9y4eeCJRmG9p4YKfqYIx</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.504</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2160</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>0.007230</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>0.650</td>\n",
       "      <td>111.904</td>\n",
       "      <td>262467</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00cqd6ZsSkLZqGMlQCR0Zo</td>\n",
       "      <td>Baby It's Cold Outside (feat. Christina Aguilera)</td>\n",
       "      <td>CeeLo Green</td>\n",
       "      <td>I really can't stay Baby it's cold outside I'v...</td>\n",
       "      <td>41</td>\n",
       "      <td>3ssspRe42CXkhPxdc12xcp</td>\n",
       "      <td>CeeLo's Magic Moment</td>\n",
       "      <td>2012-10-29</td>\n",
       "      <td>Christmas Soul</td>\n",
       "      <td>6FZYc2BvF7tColxO8PBShV</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.819</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.68900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.405</td>\n",
       "      <td>118.593</td>\n",
       "      <td>243067</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00emjlCv9azBN0fzuuyLqy</td>\n",
       "      <td>Dumb Litty</td>\n",
       "      <td>KARD</td>\n",
       "      <td>Get up out of my business You don't keep me fr...</td>\n",
       "      <td>65</td>\n",
       "      <td>7h5X3xhh3peIK9Y0qI5hbK</td>\n",
       "      <td>KARD 2nd Digital Single ‘Dumb Litty’</td>\n",
       "      <td>2019-09-22</td>\n",
       "      <td>K-Party Dance Mix</td>\n",
       "      <td>37i9dQZF1DX4RDXswvP6Mj</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.993</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.240</td>\n",
       "      <td>130.018</td>\n",
       "      <td>193160</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18449</th>\n",
       "      <td>7zXzWCVuz7whIuYZyEAlxt</td>\n",
       "      <td>Rising Like The Sun - Radio Mix</td>\n",
       "      <td>Qulinez</td>\n",
       "      <td>Caught up in such a head rush, wide-eyed latel...</td>\n",
       "      <td>0</td>\n",
       "      <td>1l4aoukbPgi5u2OaE2R4Zj</td>\n",
       "      <td>Rising Like The Sun</td>\n",
       "      <td>2014-03-24</td>\n",
       "      <td>♥ EDM LOVE 2020</td>\n",
       "      <td>6jI1gFr6ANFtT8MmTvA2Ux</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.778</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>0.00555</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.211</td>\n",
       "      <td>128.012</td>\n",
       "      <td>208656</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18450</th>\n",
       "      <td>7zycSpvjDcqh6YT1FEl2kY</td>\n",
       "      <td>Anaconda</td>\n",
       "      <td>Nicki Minaj</td>\n",
       "      <td>My anaconda don't, my anaconda don't My anacon...</td>\n",
       "      <td>49</td>\n",
       "      <td>5qs8T6ZHSrnllnOuUk6muC</td>\n",
       "      <td>The Pinkprint (Deluxe Edition)</td>\n",
       "      <td>2014-12-15</td>\n",
       "      <td>10er Playlist</td>\n",
       "      <td>1kEczIkZH8IgaWT2BiApxZ</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1800</td>\n",
       "      <td>0.06730</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.2140</td>\n",
       "      <td>0.647</td>\n",
       "      <td>129.990</td>\n",
       "      <td>260240</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18451</th>\n",
       "      <td>7zye9v6B785eFWEFYs13C2</td>\n",
       "      <td>Bound</td>\n",
       "      <td>Ponderosa Twins Plus One</td>\n",
       "      <td>Bound, bound Bound, bound Bound to fall in lov...</td>\n",
       "      <td>40</td>\n",
       "      <td>1xdgLmTFMSyJyI5DJOOX7T</td>\n",
       "      <td>2+2+1 = (Digitally Remastered)</td>\n",
       "      <td>2013-07-09</td>\n",
       "      <td>Sexy Soul 2020</td>\n",
       "      <td>5EMARioe9z9eKOeWIAC2JW</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.71500</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.657</td>\n",
       "      <td>142.218</td>\n",
       "      <td>191205</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18452</th>\n",
       "      <td>7zyLObYw4QUKQDyZOb4J0Y</td>\n",
       "      <td>I'll Do 4 U (Re-Recorded / Remastered)</td>\n",
       "      <td>Father MC</td>\n",
       "      <td>(Would you do for me) Sweetheart (Would you do...</td>\n",
       "      <td>36</td>\n",
       "      <td>14HYMxFhpgDIr9cci1u0kt</td>\n",
       "      <td>I'll Do 4 U (Re-Recorded / Remastered)</td>\n",
       "      <td>2010-10-01</td>\n",
       "      <td>New Jack Swing/ R&amp;B Hits: 1987 - 2002</td>\n",
       "      <td>4sji14lrB5bgcr51lPALYH</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.920</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.14300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.810</td>\n",
       "      <td>109.536</td>\n",
       "      <td>223890</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18453</th>\n",
       "      <td>7zzZmpw8L66ZPjH1M6qmOs</td>\n",
       "      <td>Migraine</td>\n",
       "      <td>Moonstar88</td>\n",
       "      <td>Oo nga pala, hindi nga pala tayo Hanggang dito...</td>\n",
       "      <td>61</td>\n",
       "      <td>4t3FtECyV1gClHmpBhXSfB</td>\n",
       "      <td>When I Met You</td>\n",
       "      <td>2008-07-28</td>\n",
       "      <td>Pinoy Classic Rock</td>\n",
       "      <td>37i9dQZF1DWYDQ8wBxd7xt</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>0.21700</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.221</td>\n",
       "      <td>115.049</td>\n",
       "      <td>267960</td>\n",
       "      <td>tl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18454 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     track_id  \\\n",
       "0      0017A6SJgTbfQVU2EtsPNo   \n",
       "1      004s3t0ONYlzxII9PLgU6z   \n",
       "2      00chLpzhgVjxs1zKC9UScL   \n",
       "3      00cqd6ZsSkLZqGMlQCR0Zo   \n",
       "4      00emjlCv9azBN0fzuuyLqy   \n",
       "...                       ...   \n",
       "18449  7zXzWCVuz7whIuYZyEAlxt   \n",
       "18450  7zycSpvjDcqh6YT1FEl2kY   \n",
       "18451  7zye9v6B785eFWEFYs13C2   \n",
       "18452  7zyLObYw4QUKQDyZOb4J0Y   \n",
       "18453  7zzZmpw8L66ZPjH1M6qmOs   \n",
       "\n",
       "                                              track_name  \\\n",
       "0                                               Pangarap   \n",
       "1                                           I Feel Alive   \n",
       "2                                                 Poison   \n",
       "3      Baby It's Cold Outside (feat. Christina Aguilera)   \n",
       "4                                             Dumb Litty   \n",
       "...                                                  ...   \n",
       "18449                    Rising Like The Sun - Radio Mix   \n",
       "18450                                           Anaconda   \n",
       "18451                                              Bound   \n",
       "18452             I'll Do 4 U (Re-Recorded / Remastered)   \n",
       "18453                                           Migraine   \n",
       "\n",
       "                   track_artist  \\\n",
       "0               Barbie's Cradle   \n",
       "1                 Steady Rollin   \n",
       "2                Bell Biv DeVoe   \n",
       "3                   CeeLo Green   \n",
       "4                          KARD   \n",
       "...                         ...   \n",
       "18449                   Qulinez   \n",
       "18450               Nicki Minaj   \n",
       "18451  Ponderosa Twins Plus One   \n",
       "18452                 Father MC   \n",
       "18453                Moonstar88   \n",
       "\n",
       "                                                  lyrics  track_popularity  \\\n",
       "0      Minsan pa Nang ako'y napalingon Hindi ko alam ...                41   \n",
       "1      The trees, are singing in the wind The sky blu...                28   \n",
       "2      NA Yeah, Spyderman and Freeze in full effect U...                 0   \n",
       "3      I really can't stay Baby it's cold outside I'v...                41   \n",
       "4      Get up out of my business You don't keep me fr...                65   \n",
       "...                                                  ...               ...   \n",
       "18449  Caught up in such a head rush, wide-eyed latel...                 0   \n",
       "18450  My anaconda don't, my anaconda don't My anacon...                49   \n",
       "18451  Bound, bound Bound, bound Bound to fall in lov...                40   \n",
       "18452  (Would you do for me) Sweetheart (Would you do...                36   \n",
       "18453  Oo nga pala, hindi nga pala tayo Hanggang dito...                61   \n",
       "\n",
       "               track_album_id                        track_album_name  \\\n",
       "0      1srJQ0njEQgd8w4XSqI4JQ                                    Trip   \n",
       "1      3z04Lb9Dsilqw68SHt6jLB                             Love & Loss   \n",
       "2      6oZ6brjB8x3GoeSYdwJdPc                                    Gold   \n",
       "3      3ssspRe42CXkhPxdc12xcp                    CeeLo's Magic Moment   \n",
       "4      7h5X3xhh3peIK9Y0qI5hbK    KARD 2nd Digital Single ‘Dumb Litty’   \n",
       "...                       ...                                     ...   \n",
       "18449  1l4aoukbPgi5u2OaE2R4Zj                     Rising Like The Sun   \n",
       "18450  5qs8T6ZHSrnllnOuUk6muC          The Pinkprint (Deluxe Edition)   \n",
       "18451  1xdgLmTFMSyJyI5DJOOX7T          2+2+1 = (Digitally Remastered)   \n",
       "18452  14HYMxFhpgDIr9cci1u0kt  I'll Do 4 U (Re-Recorded / Remastered)   \n",
       "18453  4t3FtECyV1gClHmpBhXSfB                          When I Met You   \n",
       "\n",
       "      track_album_release_date  \\\n",
       "0                   2001-01-01   \n",
       "1                   2017-11-21   \n",
       "2                   2005-01-01   \n",
       "3                   2012-10-29   \n",
       "4                   2019-09-22   \n",
       "...                        ...   \n",
       "18449               2014-03-24   \n",
       "18450               2014-12-15   \n",
       "18451               2013-07-09   \n",
       "18452               2010-10-01   \n",
       "18453               2008-07-28   \n",
       "\n",
       "                                           playlist_name  \\\n",
       "0                                     Pinoy Classic Rock   \n",
       "1                                      Hard Rock Workout   \n",
       "2      Back in the day - R&B, New Jack Swing, Swingbe...   \n",
       "3                                         Christmas Soul   \n",
       "4                                      K-Party Dance Mix   \n",
       "...                                                  ...   \n",
       "18449                                    ♥ EDM LOVE 2020   \n",
       "18450                                      10er Playlist   \n",
       "18451                                     Sexy Soul 2020   \n",
       "18452              New Jack Swing/ R&B Hits: 1987 - 2002   \n",
       "18453                                 Pinoy Classic Rock   \n",
       "\n",
       "                  playlist_id  ... loudness mode  speechiness  acousticness  \\\n",
       "0      37i9dQZF1DWYDQ8wBxd7xt  ...  -10.068    1       0.0236       0.27900   \n",
       "1      3YouF0u7waJnolytf9JCXf  ...   -4.739    1       0.0442       0.01170   \n",
       "2      3a9y4eeCJRmG9p4YKfqYIx  ...   -7.504    0       0.2160       0.00432   \n",
       "3      6FZYc2BvF7tColxO8PBShV  ...   -5.819    0       0.0341       0.68900   \n",
       "4      37i9dQZF1DX4RDXswvP6Mj  ...   -1.993    1       0.0409       0.03700   \n",
       "...                       ...  ...      ...  ...          ...           ...   \n",
       "18449  6jI1gFr6ANFtT8MmTvA2Ux  ...   -5.778    0       0.0878       0.00555   \n",
       "18450  1kEczIkZH8IgaWT2BiApxZ  ...   -6.224    1       0.1800       0.06730   \n",
       "18451  5EMARioe9z9eKOeWIAC2JW  ...   -6.457    0       0.0270       0.71500   \n",
       "18452  4sji14lrB5bgcr51lPALYH  ...   -4.920    0       0.0633       0.14300   \n",
       "18453  37i9dQZF1DWYDQ8wBxd7xt  ...   -6.000    1       0.0290       0.21700   \n",
       "\n",
       "       instrumentalness  liveness  valence    tempo  duration_ms  language  \n",
       "0              0.011700    0.0887    0.566   97.091       235440        tl  \n",
       "1              0.009940    0.3470    0.404  135.225       373512        en  \n",
       "2              0.007230    0.4890    0.650  111.904       262467        en  \n",
       "3              0.000000    0.0664    0.405  118.593       243067        en  \n",
       "4              0.000000    0.1380    0.240  130.018       193160        en  \n",
       "...                 ...       ...      ...      ...          ...       ...  \n",
       "18449          0.000000    0.3350    0.211  128.012       208656        en  \n",
       "18450          0.000006    0.2140    0.647  129.990       260240        en  \n",
       "18451          0.000428    0.1150    0.657  142.218       191205        en  \n",
       "18452          0.000000    0.0720    0.810  109.536       223890        en  \n",
       "18453          0.000003    0.1180    0.221  115.049       267960        tl  \n",
       "\n",
       "[18454 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3d5a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sorted = data.sort_values(by='track_album_release_date', ascending=False) # Sort by popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c8fee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368     2020-01-17\n",
       "17972    2020-01-17\n",
       "7976     2020-01-17\n",
       "10860    2020-01-17\n",
       "6499     2020-01-17\n",
       "            ...    \n",
       "3812           1960\n",
       "17632          1960\n",
       "10348    1958-03-21\n",
       "15780       1957-03\n",
       "17188    1957-01-01\n",
       "Name: track_album_release_date, Length: 18454, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sorted['track_album_release_date'] # Looking at release date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41893d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18454"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97dd5cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15405"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['language'] == 'en'] # Remove non-English lyrics\n",
    "\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9357f495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15405"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(how='any', inplace=True) # Drop any rows with missing values\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0e6493d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13726"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates(subset=['track_name', 'track_artist'], keep='first') # Drop duplicate songs\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "706dcdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['track_name', 'track_artist', 'lyrics', 'track_popularity']] # Get our column subset\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81c48378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I Feel Alive</td>\n",
       "      <td>Steady Rollin</td>\n",
       "      <td>the trees are singing in the wind the sky blue...</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Poison</td>\n",
       "      <td>Bell Biv DeVoe</td>\n",
       "      <td>na yeah spyderman and freeze in full effect uh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Baby It's Cold Outside (feat. Christina Aguilera)</td>\n",
       "      <td>CeeLo Green</td>\n",
       "      <td>i really cant stay baby its cold outside ive g...</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dumb Litty</td>\n",
       "      <td>KARD</td>\n",
       "      <td>get up out of my business you dont keep me fro...</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Soldier</td>\n",
       "      <td>James TW</td>\n",
       "      <td>hold your breath dont look down keep trying da...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>Sick Feeling</td>\n",
       "      <td>boy pablo</td>\n",
       "      <td>i had to catch the bus alarm was shaking oh al...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13722</th>\n",
       "      <td>Some Way</td>\n",
       "      <td>NAV</td>\n",
       "      <td>yeah nah nah nah nah nah nah nah nah nah nah n...</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13723</th>\n",
       "      <td>Rising Like The Sun - Radio Mix</td>\n",
       "      <td>Qulinez</td>\n",
       "      <td>caught up in such a head rush wideeyed lately ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13724</th>\n",
       "      <td>Bound</td>\n",
       "      <td>Ponderosa Twins Plus One</td>\n",
       "      <td>bound bound bound bound bound to fall in love ...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>I'll Do 4 U (Re-Recorded / Remastered)</td>\n",
       "      <td>Father MC</td>\n",
       "      <td>would you do for me sweetheart would you do fo...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13726 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              track_name  \\\n",
       "0                                           I Feel Alive   \n",
       "1                                                 Poison   \n",
       "2      Baby It's Cold Outside (feat. Christina Aguilera)   \n",
       "3                                             Dumb Litty   \n",
       "4                                                Soldier   \n",
       "...                                                  ...   \n",
       "13721                                       Sick Feeling   \n",
       "13722                                           Some Way   \n",
       "13723                    Rising Like The Sun - Radio Mix   \n",
       "13724                                              Bound   \n",
       "13725             I'll Do 4 U (Re-Recorded / Remastered)   \n",
       "\n",
       "                   track_artist  \\\n",
       "0                 Steady Rollin   \n",
       "1                Bell Biv DeVoe   \n",
       "2                   CeeLo Green   \n",
       "3                          KARD   \n",
       "4                      James TW   \n",
       "...                         ...   \n",
       "13721                 boy pablo   \n",
       "13722                       NAV   \n",
       "13723                   Qulinez   \n",
       "13724  Ponderosa Twins Plus One   \n",
       "13725                 Father MC   \n",
       "\n",
       "                                                  lyrics  track_popularity  \n",
       "0      the trees are singing in the wind the sky blue...                28  \n",
       "1      na yeah spyderman and freeze in full effect uh...                 0  \n",
       "2      i really cant stay baby its cold outside ive g...                41  \n",
       "3      get up out of my business you dont keep me fro...                65  \n",
       "4      hold your breath dont look down keep trying da...                70  \n",
       "...                                                  ...               ...  \n",
       "13721  i had to catch the bus alarm was shaking oh al...                64  \n",
       "13722  yeah nah nah nah nah nah nah nah nah nah nah n...                72  \n",
       "13723  caught up in such a head rush wideeyed lately ...                 0  \n",
       "13724  bound bound bound bound bound to fall in love ...                40  \n",
       "13725  would you do for me sweetheart would you do fo...                36  \n",
       "\n",
       "[13726 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up the lyrics\n",
    "def clean_lyrics(df, column_name):\n",
    "    df[column_name] = df[column_name].str.lower()\n",
    "    \n",
    "    df[column_name] = df[column_name].apply(lambda x: re.sub(r'[^\\w\\s]', '', x))\n",
    "    df[column_name] = df[column_name].apply(lambda x: re.sub(r'\\s+', ' ', x.strip()))\n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "data = clean_lyrics(data, 'lyrics')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf655ea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memories</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>heres to the ones that we got cheers to the wi...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Box</td>\n",
       "      <td>Roddy Ricch</td>\n",
       "      <td>pullin out the coupe at the lot told em fuck 1...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>yeah ive been tryna call ive been on my own fo...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Circles</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>oh oh oh oh oh oh oh oh oh oh oh we couldnt tu...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't Start Now</td>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td>if you dont wanna see me did a full 180 crazy ...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>Sureno Vida</td>\n",
       "      <td>Brownside</td>\n",
       "      <td>sureño vida thats what we gonna call this moth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13722</th>\n",
       "      <td>WW III</td>\n",
       "      <td>Ruff Ryders</td>\n",
       "      <td>ruff ryders ruff ryders ryde or die volume 2 t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13723</th>\n",
       "      <td>So Many Tears</td>\n",
       "      <td>2Pac</td>\n",
       "      <td>i shall not fear no man but god though i walk ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13724</th>\n",
       "      <td>Teddy's Jam</td>\n",
       "      <td>Guy</td>\n",
       "      <td>attention this is a interruption stay tuned fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>hello hello allow me to introduce myself mysel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13726 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            track_name track_artist  \\\n",
       "0             Memories     Maroon 5   \n",
       "1              The Box  Roddy Ricch   \n",
       "2      Blinding Lights   The Weeknd   \n",
       "3              Circles  Post Malone   \n",
       "4      Don't Start Now     Dua Lipa   \n",
       "...                ...          ...   \n",
       "13721      Sureno Vida    Brownside   \n",
       "13722           WW III  Ruff Ryders   \n",
       "13723    So Many Tears         2Pac   \n",
       "13724      Teddy's Jam          Guy   \n",
       "13725            Hello       Eminem   \n",
       "\n",
       "                                                  lyrics  track_popularity  \n",
       "0      heres to the ones that we got cheers to the wi...                98  \n",
       "1      pullin out the coupe at the lot told em fuck 1...                98  \n",
       "2      yeah ive been tryna call ive been on my own fo...                98  \n",
       "3      oh oh oh oh oh oh oh oh oh oh oh we couldnt tu...                98  \n",
       "4      if you dont wanna see me did a full 180 crazy ...                97  \n",
       "...                                                  ...               ...  \n",
       "13721  sureño vida thats what we gonna call this moth...                 0  \n",
       "13722  ruff ryders ruff ryders ryde or die volume 2 t...                 0  \n",
       "13723  i shall not fear no man but god though i walk ...                 0  \n",
       "13724  attention this is a interruption stay tuned fo...                 0  \n",
       "13725  hello hello allow me to introduce myself mysel...                 0  \n",
       "\n",
       "[13726 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.sort_values(by='track_popularity', ascending=False) # Sort data by popularity just for clarity\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e791e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into two datasets temporarily\n",
    "# They will be merged later\n",
    "popularity_cutoff = 50\n",
    "popular_data = data[data['track_popularity'] > popularity_cutoff] \n",
    "unpopular_data = data[data['track_popularity'] <= popularity_cutoff]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a9d2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6001\n",
      "7725\n"
     ]
    }
   ],
   "source": [
    "print(len(popular_data))\n",
    "print(len(unpopular_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4e62059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memories</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>heres to the ones that we got cheers to the wi...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Box</td>\n",
       "      <td>Roddy Ricch</td>\n",
       "      <td>pullin out the coupe at the lot told em fuck 1...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>yeah ive been tryna call ive been on my own fo...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Circles</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>oh oh oh oh oh oh oh oh oh oh oh we couldnt tu...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't Start Now</td>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td>if you dont wanna see me did a full 180 crazy ...</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>Write It Down</td>\n",
       "      <td>Hamzaa</td>\n",
       "      <td>i put it all in the song i hope you hear this ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>Cloud 9 - Original TV Movie Soundtrack</td>\n",
       "      <td>Dove Cameron</td>\n",
       "      <td>wakin up ready for some action strapin in read...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>Infinite</td>\n",
       "      <td>Habstrakt</td>\n",
       "      <td>everyone should know i wont feel alone when yo...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>Carry On - Acoustic</td>\n",
       "      <td>Young Rising Sons</td>\n",
       "      <td>oh my love dont you worry when the world gets ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>C O O L - Radio Edit</td>\n",
       "      <td>Le Youth</td>\n",
       "      <td>its me and you now ive been waiting baby tell ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6001 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  track_name       track_artist  \\\n",
       "0                                   Memories           Maroon 5   \n",
       "1                                    The Box        Roddy Ricch   \n",
       "2                            Blinding Lights         The Weeknd   \n",
       "3                                    Circles        Post Malone   \n",
       "4                            Don't Start Now           Dua Lipa   \n",
       "...                                      ...                ...   \n",
       "5996                           Write It Down             Hamzaa   \n",
       "5997  Cloud 9 - Original TV Movie Soundtrack       Dove Cameron   \n",
       "5998                                Infinite          Habstrakt   \n",
       "5999                     Carry On - Acoustic  Young Rising Sons   \n",
       "6000                    C O O L - Radio Edit           Le Youth   \n",
       "\n",
       "                                                 lyrics  track_popularity  \n",
       "0     heres to the ones that we got cheers to the wi...                98  \n",
       "1     pullin out the coupe at the lot told em fuck 1...                98  \n",
       "2     yeah ive been tryna call ive been on my own fo...                98  \n",
       "3     oh oh oh oh oh oh oh oh oh oh oh we couldnt tu...                98  \n",
       "4     if you dont wanna see me did a full 180 crazy ...                97  \n",
       "...                                                 ...               ...  \n",
       "5996  i put it all in the song i hope you hear this ...                51  \n",
       "5997  wakin up ready for some action strapin in read...                51  \n",
       "5998  everyone should know i wont feel alone when yo...                51  \n",
       "5999  oh my love dont you worry when the world gets ...                51  \n",
       "6000  its me and you now ive been waiting baby tell ...                51  \n",
       "\n",
       "[6001 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7a0533f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>Love - Remastered 2010</td>\n",
       "      <td>John Lennon</td>\n",
       "      <td>love is real real is love love is feeling feel...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>Atmosphere - 2010 Remaster</td>\n",
       "      <td>Joy Division</td>\n",
       "      <td>walk in silence dont walk away in silence see ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>While My Guitar Gently Weeps</td>\n",
       "      <td>Regina Spektor</td>\n",
       "      <td>na i look at you all see the love there thats ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>What You're Made Of</td>\n",
       "      <td>Arrested Youth</td>\n",
       "      <td>i still act like i did back in the sixth grade...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>No Strings Attached</td>\n",
       "      <td>SWACQ</td>\n",
       "      <td>come on children now were gonna have a little ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>Sureno Vida</td>\n",
       "      <td>Brownside</td>\n",
       "      <td>sureño vida thats what we gonna call this moth...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13722</th>\n",
       "      <td>WW III</td>\n",
       "      <td>Ruff Ryders</td>\n",
       "      <td>ruff ryders ruff ryders ryde or die volume 2 t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13723</th>\n",
       "      <td>So Many Tears</td>\n",
       "      <td>2Pac</td>\n",
       "      <td>i shall not fear no man but god though i walk ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13724</th>\n",
       "      <td>Teddy's Jam</td>\n",
       "      <td>Guy</td>\n",
       "      <td>attention this is a interruption stay tuned fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>hello hello allow me to introduce myself mysel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7725 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         track_name    track_artist  \\\n",
       "6001         Love - Remastered 2010     John Lennon   \n",
       "6002     Atmosphere - 2010 Remaster    Joy Division   \n",
       "6003   While My Guitar Gently Weeps  Regina Spektor   \n",
       "6004            What You're Made Of  Arrested Youth   \n",
       "6005            No Strings Attached           SWACQ   \n",
       "...                             ...             ...   \n",
       "13721                   Sureno Vida       Brownside   \n",
       "13722                        WW III     Ruff Ryders   \n",
       "13723                 So Many Tears            2Pac   \n",
       "13724                   Teddy's Jam             Guy   \n",
       "13725                         Hello          Eminem   \n",
       "\n",
       "                                                  lyrics  track_popularity  \n",
       "6001   love is real real is love love is feeling feel...                50  \n",
       "6002   walk in silence dont walk away in silence see ...                50  \n",
       "6003   na i look at you all see the love there thats ...                50  \n",
       "6004   i still act like i did back in the sixth grade...                50  \n",
       "6005   come on children now were gonna have a little ...                50  \n",
       "...                                                  ...               ...  \n",
       "13721  sureño vida thats what we gonna call this moth...                 0  \n",
       "13722  ruff ryders ruff ryders ryde or die volume 2 t...                 0  \n",
       "13723  i shall not fear no man but god though i walk ...                 0  \n",
       "13724  attention this is a interruption stay tuned fo...                 0  \n",
       "13725  hello hello allow me to introduce myself mysel...                 0  \n",
       "\n",
       "[7725 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpopular_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c57d56",
   "metadata": {},
   "source": [
    "## Getting features\n",
    "\n",
    "- diversity per song\n",
    "- explicit language per song\n",
    "- average word length\n",
    "- frequency of uncommon words\n",
    "- type-token ratio\n",
    "- repetition\n",
    "- rhyme proportions\n",
    "- consonants per word\n",
    "- vowels per word\n",
    "- number of words\n",
    "- number of characters\n",
    "- consonant proportion\n",
    "- vowel proportion\n",
    "- pronoun type proportions\n",
    "- specific pronoun proportions\n",
    "- gendered pronoun proportions\n",
    "- named entity proportions\n",
    "- part of speech proportions\n",
    "- word similarities\n",
    "- alliteration\n",
    "- metaphors\n",
    "- similes\n",
    "- word2vec news comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9eb0f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the diversity of a set of lyrics\n",
    "def calculate_diversity(lyrics):\n",
    "    tokens = word_tokenize(lyrics.lower())\n",
    "    total_words = len(tokens)\n",
    "    unique_words = len(set(tokens))\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return unique_words / total_words\n",
    "\n",
    "popular_data['diversity'] = popular_data['lyrics'].apply(calculate_diversity)\n",
    "unpopular_data['diversity'] = unpopular_data['lyrics'].apply(calculate_diversity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd0be9e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7002a9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to check if a song's lyrics are explicit or not and also count the number of explicit words\n",
    "with open('explicit_words.txt', 'r') as file:\n",
    "    explicit_words = set(file.read().splitlines())\n",
    "\n",
    "\n",
    "def check_explicit(lyrics):\n",
    "    words = word_tokenize(lyrics.lower())\n",
    "    explicit_count = Counter([word for word in words if word in explicit_words])\n",
    "    is_explicit = int(bool(explicit_count))\n",
    "    return is_explicit, explicit_count\n",
    "\n",
    "def add_features_columns(df):\n",
    "    is_explicit_list = []\n",
    "    explicit_word_counts_list = []\n",
    "    for lyrics in df['lyrics']:\n",
    "        is_explicit, explicit_word_counts = check_explicit(lyrics)\n",
    "        is_explicit_list.append(is_explicit)\n",
    "        explicit_word_counts_list.append(explicit_word_counts)\n",
    "    df['is_explicit'] = is_explicit_list\n",
    "    df['explicit_word_counts'] = explicit_word_counts_list\n",
    "\n",
    "\n",
    "add_features_columns(popular_data)\n",
    "add_features_columns(unpopular_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c412c7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff70725",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f4015f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the average word length\n",
    "def average_word_length(lyrics):\n",
    "    words = lyrics.split()\n",
    "    if len(words) == 0:\n",
    "        return 0\n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "\n",
    "def add_average_word_length_column(df):\n",
    "    df['average_word_length'] = df['lyrics'].apply(average_word_length)\n",
    "\n",
    "add_average_word_length_column(popular_data)\n",
    "add_average_word_length_column(unpopular_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2640051",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa50b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get the uncommon words in the lyrics\n",
    "def calculate_word_frequency(corpus):\n",
    "    words = ' '.join(corpus).split()\n",
    "    return Counter(words)\n",
    "\n",
    "def identify_uncommon_words(lyrics, common_words):\n",
    "    words = lyrics.split()\n",
    "    return [word for word in words if word not in common_words]\n",
    "\n",
    "popular_word_frequencies = calculate_word_frequency(popular_data['lyrics'])\n",
    "unpopular_word_frequencies = calculate_word_frequency(unpopular_data['lyrics'])\n",
    "\n",
    "common_threshold = 3\n",
    "common_words_popular = {word for word, freq in popular_word_frequencies.items() if freq > common_threshold}\n",
    "common_words_unpopular = {word for word, freq in unpopular_word_frequencies.items() if freq > common_threshold}\n",
    "\n",
    "popular_data['uncommon_words'] = popular_data['lyrics'].apply(lambda x: \\\n",
    "                                                              identify_uncommon_words(x, common_words_popular))\n",
    "unpopular_data['uncommon_words'] = unpopular_data['lyrics'].apply(lambda x: \\\n",
    "                                                                  identify_uncommon_words(x, \n",
    "                                                                                          common_words_unpopular))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923949e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25f720bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the TTR for a set of lyrics\n",
    "def calculate_ttr(lyrics):\n",
    "    words = lyrics.split()\n",
    "    total_words = len(words)\n",
    "    unique_words = len(set(words))\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    return unique_words / total_words\n",
    "\n",
    "popular_data['TTR'] = popular_data['lyrics'].apply(calculate_ttr)\n",
    "unpopular_data['TTR'] = unpopular_data['lyrics'].apply(calculate_ttr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1699bf9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74e98970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get a measure of the repetition in a set of lyrics\n",
    "def calculate_repetition(lyrics):\n",
    "    words = lyrics.split()\n",
    "    word_sequences = [tuple(words[i:i+3]) for i in range(len(words)-2)]  \n",
    "    repetition_count = len(words) - len(set(word_sequences))\n",
    "    repetition_normalized = repetition_count / len(words)\n",
    "    return repetition_normalized\n",
    "\n",
    "popular_data['repetition'] = popular_data['lyrics'].apply(calculate_repetition)\n",
    "unpopular_data['repetition'] = unpopular_data['lyrics'].apply(calculate_repetition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e1d76a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>diversity</th>\n",
       "      <th>is_explicit</th>\n",
       "      <th>explicit_word_counts</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>uncommon_words</th>\n",
       "      <th>TTR</th>\n",
       "      <th>repetition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>One More Time</td>\n",
       "      <td>Daft Punk</td>\n",
       "      <td>na one more time one more time one more time w...</td>\n",
       "      <td>74</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>4.393593</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.048055</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        track_name track_artist  \\\n",
       "823  One More Time    Daft Punk   \n",
       "\n",
       "                                                lyrics  track_popularity  \\\n",
       "823  na one more time one more time one more time w...                74   \n",
       "\n",
       "     diversity  is_explicit explicit_word_counts  average_word_length  \\\n",
       "823   0.045455            0                   {}             4.393593   \n",
       "\n",
       "    uncommon_words       TTR  repetition  \n",
       "823             []  0.048055    0.891304  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_data[popular_data['track_name'] == 'One More Time'] # Checking the metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11900d6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bdf4232e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to see what proportion of a set of lyrics have rhyme patterns\n",
    "def calculate_rhyme_proportion(lyrics):\n",
    "    words = re.findall(r'\\b\\w+\\b', lyrics.lower())  \n",
    "    rhyme_count = 0\n",
    "    total_word_count = len(words)\n",
    "    for i in range(total_word_count - 1):\n",
    "        if words[i][-2:] == words[i + 1][-2:]:  \n",
    "            rhyme_count += 1\n",
    "    return rhyme_count / max(total_word_count - 1, 1) \n",
    "\n",
    "\n",
    "popular_data['rhyme_proportion'] = popular_data['lyrics'].apply(calculate_rhyme_proportion)\n",
    "unpopular_data['rhyme_proportion'] = unpopular_data['lyrics'].apply(calculate_rhyme_proportion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0d6c13",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7e32d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to count words, consonants and vowels and get metrics about them for a set of lyrics\n",
    "def count_consonants(word):\n",
    "    vowels = 'aeiou'\n",
    "    consonant_count = sum(1 for letter in word if letter.isalpha() and letter.lower() not in vowels)\n",
    "    return consonant_count\n",
    "\n",
    "def count_vowels(word):\n",
    "    vowels = 'aeiou'\n",
    "    vowel_count = sum(1 for letter in word if letter.isalpha() and letter.lower() in vowels)\n",
    "    return vowel_count\n",
    "\n",
    "def calculate_metrics(lyrics):\n",
    "    words = lyrics.split()\n",
    "    num_words = len(words)\n",
    "    num_characters = sum(len(word) for word in words)\n",
    "    num_consonants = sum(count_consonants(word) for word in words)\n",
    "    num_vowels = sum(count_vowels(word) for word in words)\n",
    "    consonant_proportion = num_consonants / max(num_characters, 1)\n",
    "    vowel_proportion = num_vowels / max(num_characters, 1)\n",
    "    return pd.Series({\n",
    "        'num_words': num_words,\n",
    "        'num_characters': num_characters,\n",
    "        'num_consonants': num_consonants,\n",
    "        'num_vowels': num_vowels,\n",
    "        'consonant_proportion': consonant_proportion,\n",
    "        'vowel_proportion': vowel_proportion\n",
    "    })\n",
    "\n",
    "popular_data = popular_data.join(popular_data['lyrics'].apply(calculate_metrics))\n",
    "unpopular_data = unpopular_data.join(unpopular_data['lyrics'].apply(calculate_metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ac2918",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82dddf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to determine the consonants and vowels per word for a set of lyrics\n",
    "def calculate_consonants_per_word(lyrics):\n",
    "    words = lyrics.split()\n",
    "    num_words = len(words)\n",
    "    num_consonants = sum(count_consonants(word) for word in words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num_consonants / num_words\n",
    "\n",
    "def calculate_vowels_per_word(lyrics):\n",
    "    words = lyrics.split()\n",
    "    num_words = len(words)\n",
    "    num_vowels = sum(count_vowels(word) for word in words)\n",
    "    if num_words == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return num_vowels / num_words\n",
    "\n",
    "popular_data['consonants_per_word'] = popular_data['lyrics'].apply(calculate_consonants_per_word)\n",
    "popular_data['vowels_per_word'] = popular_data['lyrics'].apply(calculate_vowels_per_word)\n",
    "\n",
    "unpopular_data['consonants_per_word'] = unpopular_data['lyrics'].apply(calculate_consonants_per_word)\n",
    "unpopular_data['vowels_per_word'] = unpopular_data['lyrics'].apply(calculate_vowels_per_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a47b0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9cb91c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to determine the proportion of pronoun types in a set of lyrics \n",
    "def get_pos_tags(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    pos_tags = nltk.pos_tag(tokens)\n",
    "    return pos_tags\n",
    "\n",
    "def count_pronouns(pos_tags):\n",
    "    pronouns = ['PRP', 'PRP$', 'WP', 'WP$']\n",
    "    pronoun_count = sum(1 for _, tag in pos_tags if tag in pronouns)\n",
    "    return pronoun_count\n",
    "\n",
    "def calculate_pronoun_proportion(lyrics):\n",
    "    pos_tags = get_pos_tags(lyrics)\n",
    "    total_words = len(pos_tags)\n",
    "    pronoun_count = count_pronouns(pos_tags)\n",
    "    if total_words == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return pronoun_count / total_words\n",
    "\n",
    "popular_data['pronoun_proportion'] = popular_data['lyrics'].apply(calculate_pronoun_proportion)\n",
    "unpopular_data['pronoun_proportion'] = unpopular_data['lyrics'].apply(calculate_pronoun_proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28b7474",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9148f829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine specific pronoun proportions in the set of input lyrics\n",
    "pronouns = [\n",
    "    'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them',\n",
    "    'mine', 'yours', 'his', 'hers', 'its', 'ours', 'theirs',\n",
    "    'myself', 'yourself', 'himself', 'herself', 'itself', 'ourselves', 'yourselves', 'themselves',\n",
    "    'this', 'that', 'these', 'those',\n",
    "    'who', 'whom', 'whose', 'which', 'what',\n",
    "    'anybody', 'anyone', 'anything', 'somebody', 'someone', 'something', 'nobody', 'none', 'no one', 'nothing',\n",
    "    'each', 'either', 'neither', 'few', 'many', 'several', 'some', 'all', 'more', 'most', 'other', 'several', \n",
    "    'such'\n",
    "]\n",
    "\n",
    "def calculate_pronoun_proportions(lyrics):\n",
    "    words = lyrics.lower().split()\n",
    "    total_words = len(words)\n",
    "    pronoun_counts = Counter(words)\n",
    "    pronoun_proportions = {pronoun: pronoun_counts.get(pronoun, 0) / total_words for pronoun in pronouns if pronoun_counts.get(pronoun, 0) > 0}\n",
    "    return pronoun_proportions\n",
    "\n",
    "popular_data['specific_pronoun_proportions'] = popular_data['lyrics'].apply(calculate_pronoun_proportions)\n",
    "unpopular_data['specific_pronoun_proportions'] = unpopular_data['lyrics'].apply(calculate_pronoun_proportions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf1aff8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40c81efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the gendered pronoun proportions for lyrics\n",
    "def calculate_gender_proportions(pronoun_proportions):\n",
    "    total_pronouns = sum(pronoun_proportions.values())\n",
    "    male_pronouns = sum(pronoun_proportions.get(pronoun, 0) for pronoun in ['he', 'him', 'his', 'himself'])\n",
    "    female_pronouns = sum(pronoun_proportions.get(pronoun, 0) for pronoun in ['she', 'her', 'hers', 'herself'])\n",
    "    neutral_pronouns = total_pronouns - male_pronouns - female_pronouns\n",
    "    prop_male = male_pronouns / total_pronouns if total_pronouns > 0 else 0\n",
    "    prop_female = female_pronouns / total_pronouns if total_pronouns > 0 else 0\n",
    "    prop_neutral = neutral_pronouns / total_pronouns if total_pronouns > 0 else 0\n",
    "    return prop_male, prop_female, prop_neutral\n",
    "\n",
    "\n",
    "popular_data['prop_male_pronouns'], popular_data['prop_female_pronouns'], popular_data['prop_neutral_pronouns'] = zip(*popular_data['specific_pronoun_proportions'].apply(calculate_gender_proportions))\n",
    "unpopular_data['prop_male_pronouns'], unpopular_data['prop_female_pronouns'], unpopular_data['prop_neutral_pronouns'] = zip(*unpopular_data['specific_pronoun_proportions'].apply(calculate_gender_proportions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f570d2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9773e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the proportions of all parts of speech in a set of input lyrics\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def calculate_pos_frequency(lyrics):\n",
    "    doc = nlp(lyrics)\n",
    "    pos_counts = Counter(token.pos_ for token in doc)\n",
    "    total_tokens = len(doc)\n",
    "    pos_frequency = {pos: count / total_tokens for pos, count in pos_counts.items()}\n",
    "    \n",
    "    return pos_frequency\n",
    "\n",
    "popular_data['pos_frequency'] = popular_data['lyrics'].apply(calculate_pos_frequency)\n",
    "unpopular_data['pos_frequency'] = unpopular_data['lyrics'].apply(calculate_pos_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1509e752",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb71466d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/theobragstad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Here we find common ngrams ranging in size from 1-5 words\n",
    "nltk.download('punkt')\n",
    "\n",
    "def find_most_common_ngrams(lyrics):\n",
    "    words = nltk.word_tokenize(lyrics.lower())\n",
    "    \n",
    "    most_common_ngrams = []\n",
    "    \n",
    "    for n in range(1, 6):\n",
    "        n_grams = ngrams(words, n)\n",
    "        \n",
    "        n_grams_counter = Counter(n_grams)\n",
    "        \n",
    "        most_common = n_grams_counter.most_common(1)\n",
    "        \n",
    "        if most_common:\n",
    "            most_common_ngrams.append(most_common[0][0])\n",
    "        else:\n",
    "            most_common_ngrams.append(None)\n",
    "    \n",
    "    return most_common_ngrams\n",
    "\n",
    "popular_data['n_grams'] = popular_data['lyrics'].apply(find_most_common_ngrams)\n",
    "unpopular_data['n_grams'] = unpopular_data['lyrics'].apply(find_most_common_ngrams)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c68e56c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5185d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to get simile, metaphor, and alliteration densities for a set of lyrics\n",
    "def simile_density(lyrics):\n",
    "    simile_pattern = r'\\b(?:like|as)\\s+[\\w\\s]+(?:like|as)\\b'\n",
    "    \n",
    "    simile_count = len(re.findall(simile_pattern, lyrics.lower()))\n",
    "    \n",
    "    total_words = len(lyrics.split())\n",
    "    \n",
    "    if total_words == 0:\n",
    "        return 0.0  \n",
    "    else:\n",
    "        normalized_simile_count = simile_count / total_words\n",
    "        return normalized_simile_count\n",
    "\n",
    "def metaphor_density(lyrics):\n",
    "    metaphor_pattern = r'\\b(?:\\w+)\\s+(?:is|was|were|are)\\s+[\\w\\s]+\\b'\n",
    "    \n",
    "    metaphor_count = len(re.findall(metaphor_pattern, lyrics.lower()))\n",
    "    \n",
    "    total_words = len(lyrics.split())\n",
    "    \n",
    "    if total_words == 0:\n",
    "        return 0.0  \n",
    "    else:\n",
    "        normalized_metaphor_count = metaphor_count / total_words\n",
    "        return normalized_metaphor_count\n",
    "\n",
    "def alliteration_density(lyrics):\n",
    "    lyrics_lower = lyrics.lower()\n",
    "    \n",
    "    alliteration_pattern = r'\\b(\\w)\\w*\\s+(\\w)\\w*\\s+(\\w)\\w*\\b'  \n",
    "    \n",
    "    alliterations = re.findall(alliteration_pattern, lyrics_lower)\n",
    "    \n",
    "    alliteration_count = len(set(alliterations))\n",
    "    \n",
    "    total_words = len(lyrics_lower.split())\n",
    "    \n",
    "    if total_words == 0:\n",
    "        return 0.0 \n",
    "    else:\n",
    "        alliteration_density = alliteration_count / total_words\n",
    "        return alliteration_density\n",
    "\n",
    "\n",
    "popular_data['simile_density'] = popular_data['lyrics'].apply(simile_density)\n",
    "unpopular_data['simile_density'] = unpopular_data['lyrics'].apply(simile_density)\n",
    "\n",
    "popular_data['metaphor_density'] = popular_data['lyrics'].apply(metaphor_density)\n",
    "unpopular_data['metaphor_density'] = unpopular_data['lyrics'].apply(metaphor_density)\n",
    "\n",
    "popular_data['alliteration_density'] = popular_data['lyrics'].apply(alliteration_density)\n",
    "unpopular_data['alliteration_density'] = unpopular_data['lyrics'].apply(alliteration_density)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591be51c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "785d298f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>diversity</th>\n",
       "      <th>is_explicit</th>\n",
       "      <th>explicit_word_counts</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>uncommon_words</th>\n",
       "      <th>TTR</th>\n",
       "      <th>...</th>\n",
       "      <th>pronoun_proportion</th>\n",
       "      <th>specific_pronoun_proportions</th>\n",
       "      <th>prop_male_pronouns</th>\n",
       "      <th>prop_female_pronouns</th>\n",
       "      <th>prop_neutral_pronouns</th>\n",
       "      <th>pos_frequency</th>\n",
       "      <th>n_grams</th>\n",
       "      <th>simile_density</th>\n",
       "      <th>metaphor_density</th>\n",
       "      <th>alliteration_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memories</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>heres to the ones that we got cheers to the wi...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>4.455696</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055696</td>\n",
       "      <td>{'i': 0.02278481012658228, 'you': 0.0303797468...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>{'NOUN': 0.21318069306930693, 'ADP': 0.0866336...</td>\n",
       "      <td>[(the,), (bring, back), (memories, bring, back...</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.056962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Box</td>\n",
       "      <td>Roddy Ricch</td>\n",
       "      <td>pullin out the coupe at the lot told em fuck 1...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fuck': 48, 'damn': 24, 'sucked': 24, 'nigga'...</td>\n",
       "      <td>3.588665</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.043876</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>{'i': 0.054844606946983544, 'you': 0.007312614...</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.84127</td>\n",
       "      <td>{'VERB': 0.17618629173989456, 'ADP': 0.0949033...</td>\n",
       "      <td>[(the,), (the, box), (i, got, the), (pullin, o...</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.078611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>yeah ive been tryna call ive been on my own fo...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.045849</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.471042</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.045849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065637</td>\n",
       "      <td>{'i': 0.08494208494208494, 'you': 0.0231660231...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>{'INTJ': 0.0989399293286219, 'PRON': 0.2049469...</td>\n",
       "      <td>[(i,), (hey, hey), (i, said, ooh), (i, said, o...</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Circles</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>oh oh oh oh oh oh oh oh oh oh oh we couldnt tu...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>1</td>\n",
       "      <td>{'sex': 10}</td>\n",
       "      <td>3.613419</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.060703</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114650</td>\n",
       "      <td>{'i': 0.04472843450479233, 'you': 0.0351437699...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>{'INTJ': 0.03343465045592705, 'PRON': 0.182370...</td>\n",
       "      <td>[(run,), (run, away), (oh, oh, oh), (run, away...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.108626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't Start Now</td>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td>if you dont wanna see me did a full 180 crazy ...</td>\n",
       "      <td>97</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.634868</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.030428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131833</td>\n",
       "      <td>{'i': 0.006578947368421052, 'you': 0.052631578...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>{'SCONJ': 0.05588235294117647, 'PRON': 0.16176...</td>\n",
       "      <td>[(dont,), (up, up), (dont, come, out), (up, do...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.057155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>Write It Down</td>\n",
       "      <td>Hamzaa</td>\n",
       "      <td>i put it all in the song i hope you hear this ...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.297688</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.395954</td>\n",
       "      <td>[mmmuh, mmmuh]</td>\n",
       "      <td>0.297688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124277</td>\n",
       "      <td>{'i': 0.08670520231213873, 'you': 0.0231213872...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>{'PRON': 0.2896174863387978, 'VERB': 0.2131147...</td>\n",
       "      <td>[(i,), (ill, write), (ill, write, it), (ill, w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.294798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>Cloud 9 - Original TV Movie Soundtrack</td>\n",
       "      <td>Dove Cameron</td>\n",
       "      <td>wakin up ready for some action strapin in read...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.331126</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.289562</td>\n",
       "      <td>[strapin, dropin, soarin, 9this, clclcloud, cl...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072848</td>\n",
       "      <td>{'i': 0.003367003367003367, 'you': 0.003367003...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>{'VERB': 0.19076923076923077, 'ADP': 0.0984615...</td>\n",
       "      <td>[(cloud,), (im, on), (im, on, cloud), (im, on,...</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>0.218855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>Infinite</td>\n",
       "      <td>Habstrakt</td>\n",
       "      <td>everyone should know i wont feel alone when yo...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>4.337209</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>{'i': 0.046511627906976744, 'you': 0.081395348...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>{'PRON': 0.23595505617977527, 'AUX': 0.0898876...</td>\n",
       "      <td>[(know,), (know, know), (know, know, know), (k...</td>\n",
       "      <td>0.011628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>Carry On - Acoustic</td>\n",
       "      <td>Young Rising Sons</td>\n",
       "      <td>oh my love dont you worry when the world gets ...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.251366</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.392857</td>\n",
       "      <td>[frayed]</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.128415</td>\n",
       "      <td>{'i': 0.06318681318681318, 'you': 0.0467032967...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>{'INTJ': 0.07349081364829396, 'PRON': 0.194225...</td>\n",
       "      <td>[(i,), (oh, i), (oh, i, know), (oh, i, know, w...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.197802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>C O O L - Radio Edit</td>\n",
       "      <td>Le Youth</td>\n",
       "      <td>its me and you now ive been waiting baby tell ...</td>\n",
       "      <td>51</td>\n",
       "      <td>0.110169</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.382353</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.231638</td>\n",
       "      <td>{'i': 0.014705882352941176, 'you': 0.094117647...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>{'PRON': 0.3047091412742382, 'CCONJ': 0.027700...</td>\n",
       "      <td>[(you,), (tell, me), (baby, tell, me), (as, lo...</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.185294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6001 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  track_name       track_artist  \\\n",
       "0                                   Memories           Maroon 5   \n",
       "1                                    The Box        Roddy Ricch   \n",
       "2                            Blinding Lights         The Weeknd   \n",
       "3                                    Circles        Post Malone   \n",
       "4                            Don't Start Now           Dua Lipa   \n",
       "...                                      ...                ...   \n",
       "5996                           Write It Down             Hamzaa   \n",
       "5997  Cloud 9 - Original TV Movie Soundtrack       Dove Cameron   \n",
       "5998                                Infinite          Habstrakt   \n",
       "5999                     Carry On - Acoustic  Young Rising Sons   \n",
       "6000                    C O O L - Radio Edit           Le Youth   \n",
       "\n",
       "                                                 lyrics  track_popularity  \\\n",
       "0     heres to the ones that we got cheers to the wi...                98   \n",
       "1     pullin out the coupe at the lot told em fuck 1...                98   \n",
       "2     yeah ive been tryna call ive been on my own fo...                98   \n",
       "3     oh oh oh oh oh oh oh oh oh oh oh we couldnt tu...                98   \n",
       "4     if you dont wanna see me did a full 180 crazy ...                97   \n",
       "...                                                 ...               ...   \n",
       "5996  i put it all in the song i hope you hear this ...                51   \n",
       "5997  wakin up ready for some action strapin in read...                51   \n",
       "5998  everyone should know i wont feel alone when yo...                51   \n",
       "5999  oh my love dont you worry when the world gets ...                51   \n",
       "6000  its me and you now ive been waiting baby tell ...                51   \n",
       "\n",
       "      diversity  is_explicit  \\\n",
       "0      0.032911            0   \n",
       "1      0.043243            1   \n",
       "2      0.045849            0   \n",
       "3      0.061146            1   \n",
       "4      0.030145            0   \n",
       "...         ...          ...   \n",
       "5996   0.297688            0   \n",
       "5997   0.331126            0   \n",
       "5998   0.302326            0   \n",
       "5999   0.251366            0   \n",
       "6000   0.110169            0   \n",
       "\n",
       "                                   explicit_word_counts  average_word_length  \\\n",
       "0                                                    {}             4.455696   \n",
       "1     {'fuck': 48, 'damn': 24, 'sucked': 24, 'nigga'...             3.588665   \n",
       "2                                                    {}             3.471042   \n",
       "3                                           {'sex': 10}             3.613419   \n",
       "4                                                    {}             3.634868   \n",
       "...                                                 ...                  ...   \n",
       "5996                                                 {}             3.395954   \n",
       "5997                                                 {}             3.289562   \n",
       "5998                                                 {}             4.337209   \n",
       "5999                                                 {}             3.392857   \n",
       "6000                                                 {}             3.382353   \n",
       "\n",
       "                                         uncommon_words       TTR  ...  \\\n",
       "0                                                    []  0.032911  ...   \n",
       "1                                                    []  0.043876  ...   \n",
       "2                                                    []  0.045849  ...   \n",
       "3                                                    []  0.060703  ...   \n",
       "4                                                    []  0.030428  ...   \n",
       "...                                                 ...       ...  ...   \n",
       "5996                                     [mmmuh, mmmuh]  0.297688  ...   \n",
       "5997  [strapin, dropin, soarin, 9this, clclcloud, cl...  0.333333  ...   \n",
       "5998                                                 []  0.302326  ...   \n",
       "5999                                           [frayed]  0.250000  ...   \n",
       "6000                                                 []  0.111765  ...   \n",
       "\n",
       "      pronoun_proportion                       specific_pronoun_proportions  \\\n",
       "0               0.055696  {'i': 0.02278481012658228, 'you': 0.0303797468...   \n",
       "1               0.066667  {'i': 0.054844606946983544, 'you': 0.007312614...   \n",
       "2               0.065637  {'i': 0.08494208494208494, 'you': 0.0231660231...   \n",
       "3               0.114650  {'i': 0.04472843450479233, 'you': 0.0351437699...   \n",
       "4               0.131833  {'i': 0.006578947368421052, 'you': 0.052631578...   \n",
       "...                  ...                                                ...   \n",
       "5996            0.124277  {'i': 0.08670520231213873, 'you': 0.0231213872...   \n",
       "5997            0.072848  {'i': 0.003367003367003367, 'you': 0.003367003...   \n",
       "5998            0.116279  {'i': 0.046511627906976744, 'you': 0.081395348...   \n",
       "5999            0.128415  {'i': 0.06318681318681318, 'you': 0.0467032967...   \n",
       "6000            0.231638  {'i': 0.014705882352941176, 'you': 0.094117647...   \n",
       "\n",
       "      prop_male_pronouns  prop_female_pronouns  prop_neutral_pronouns  \\\n",
       "0               0.000000              0.000000                1.00000   \n",
       "1               0.031746              0.126984                0.84127   \n",
       "2               0.000000              0.000000                1.00000   \n",
       "3               0.000000              0.000000                1.00000   \n",
       "4               0.000000              0.000000                1.00000   \n",
       "...                  ...                   ...                    ...   \n",
       "5996            0.000000              0.000000                1.00000   \n",
       "5997            0.000000              0.000000                1.00000   \n",
       "5998            0.000000              0.000000                1.00000   \n",
       "5999            0.000000              0.000000                1.00000   \n",
       "6000            0.000000              0.000000                1.00000   \n",
       "\n",
       "                                          pos_frequency  \\\n",
       "0     {'NOUN': 0.21318069306930693, 'ADP': 0.0866336...   \n",
       "1     {'VERB': 0.17618629173989456, 'ADP': 0.0949033...   \n",
       "2     {'INTJ': 0.0989399293286219, 'PRON': 0.2049469...   \n",
       "3     {'INTJ': 0.03343465045592705, 'PRON': 0.182370...   \n",
       "4     {'SCONJ': 0.05588235294117647, 'PRON': 0.16176...   \n",
       "...                                                 ...   \n",
       "5996  {'PRON': 0.2896174863387978, 'VERB': 0.2131147...   \n",
       "5997  {'VERB': 0.19076923076923077, 'ADP': 0.0984615...   \n",
       "5998  {'PRON': 0.23595505617977527, 'AUX': 0.0898876...   \n",
       "5999  {'INTJ': 0.07349081364829396, 'PRON': 0.194225...   \n",
       "6000  {'PRON': 0.3047091412742382, 'CCONJ': 0.027700...   \n",
       "\n",
       "                                                n_grams  simile_density  \\\n",
       "0     [(the,), (bring, back), (memories, bring, back...        0.000316   \n",
       "1     [(the,), (the, box), (i, got, the), (pullin, o...        0.000229   \n",
       "2     [(i,), (hey, hey), (i, said, ooh), (i, said, o...        0.000483   \n",
       "3     [(run,), (run, away), (oh, oh, oh), (run, away...        0.000000   \n",
       "4     [(dont,), (up, up), (dont, come, out), (up, do...        0.000000   \n",
       "...                                                 ...             ...   \n",
       "5996  [(i,), (ill, write), (ill, write, it), (ill, w...        0.000000   \n",
       "5997  [(cloud,), (im, on), (im, on, cloud), (im, on,...        0.003367   \n",
       "5998  [(know,), (know, know), (know, know, know), (k...        0.011628   \n",
       "5999  [(i,), (oh, i), (oh, i, know), (oh, i, know, w...        0.000000   \n",
       "6000  [(you,), (tell, me), (baby, tell, me), (as, lo...        0.002941   \n",
       "\n",
       "      metaphor_density  alliteration_density  \n",
       "0             0.000316              0.056962  \n",
       "1             0.000229              0.078611  \n",
       "2             0.000000              0.075290  \n",
       "3             0.000639              0.108626  \n",
       "4             0.000411              0.057155  \n",
       "...                ...                   ...  \n",
       "5996          0.002890              0.294798  \n",
       "5997          0.003367              0.218855  \n",
       "5998          0.000000              0.255814  \n",
       "5999          0.002747              0.197802  \n",
       "6000          0.002941              0.185294  \n",
       "\n",
       "[6001 rows x 30 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a4a7195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>diversity</th>\n",
       "      <th>is_explicit</th>\n",
       "      <th>explicit_word_counts</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>uncommon_words</th>\n",
       "      <th>TTR</th>\n",
       "      <th>...</th>\n",
       "      <th>pronoun_proportion</th>\n",
       "      <th>specific_pronoun_proportions</th>\n",
       "      <th>prop_male_pronouns</th>\n",
       "      <th>prop_female_pronouns</th>\n",
       "      <th>prop_neutral_pronouns</th>\n",
       "      <th>pos_frequency</th>\n",
       "      <th>n_grams</th>\n",
       "      <th>simile_density</th>\n",
       "      <th>metaphor_density</th>\n",
       "      <th>alliteration_density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6001</th>\n",
       "      <td>Love - Remastered 2010</td>\n",
       "      <td>John Lennon</td>\n",
       "      <td>love is real real is love love is feeling feel...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.746032</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.317460</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063492</td>\n",
       "      <td>{'you': 0.031746031746031744, 'we': 0.01587301...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'NOUN': 0.30158730158730157, 'AUX': 0.3015873...</td>\n",
       "      <td>[(love,), (love, is), (love, love, is), (is, l...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.301587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6002</th>\n",
       "      <td>Atmosphere - 2010 Remaster</td>\n",
       "      <td>Joy Division</td>\n",
       "      <td>walk in silence dont walk away in silence see ...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>1</td>\n",
       "      <td>{'naked': 1}</td>\n",
       "      <td>4.487805</td>\n",
       "      <td>[rebuilding, confronts]</td>\n",
       "      <td>0.646341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>{'you': 0.012195121951219513, 'it': 0.01219512...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'VERB': 0.19318181818181818, 'ADP': 0.1363636...</td>\n",
       "      <td>[(walk,), (in, silence), (dont, walk, away), (...</td>\n",
       "      <td>0.012195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6003</th>\n",
       "      <td>While My Guitar Gently Weeps</td>\n",
       "      <td>Regina Spektor</td>\n",
       "      <td>na i look at you all see the love there thats ...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>4.116883</td>\n",
       "      <td>[diverted, inverted, alerted]</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162338</td>\n",
       "      <td>{'i': 0.06493506493506493, 'you': 0.0649350649...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'PART': 0.0375, 'PRON': 0.2625, 'VERB': 0.218...</td>\n",
       "      <td>[(i,), (my, guitar), (my, guitar, gently), (my...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.266234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6004</th>\n",
       "      <td>What You're Made Of</td>\n",
       "      <td>Arrested Youth</td>\n",
       "      <td>i still act like i did back in the sixth grade...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>1</td>\n",
       "      <td>{'shit': 3, 'bitch': 3, 'hell': 9, 'fucks': 3}</td>\n",
       "      <td>3.746411</td>\n",
       "      <td>[whiny, tantrums, whiny, tantrums, whiny, tant...</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088517</td>\n",
       "      <td>{'i': 0.0430622009569378, 'you': 0.00956937799...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'PRON': 0.17647058823529413, 'ADV': 0.0565610...</td>\n",
       "      <td>[(i,), (oh, oh), (oh, oh, oh), (show, me, what...</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.183413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6005</th>\n",
       "      <td>No Strings Attached</td>\n",
       "      <td>SWACQ</td>\n",
       "      <td>come on children now were gonna have a little ...</td>\n",
       "      <td>50</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>1</td>\n",
       "      <td>{'organ': 1}</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{}</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>{'VERB': 0.21739130434782608, 'ADP': 0.1304347...</td>\n",
       "      <td>[(on,), (come, on), (come, on, children), (com...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.318182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>Sureno Vida</td>\n",
       "      <td>Brownside</td>\n",
       "      <td>sureño vida thats what we gonna call this moth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521441</td>\n",
       "      <td>1</td>\n",
       "      <td>{'motherfucker': 1, 'hell': 5, 'shit': 2, 'fuc...</td>\n",
       "      <td>4.213793</td>\n",
       "      <td>[qvo, malito, 1990, malito, explicando, realid...</td>\n",
       "      <td>0.520690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102916</td>\n",
       "      <td>{'i': 0.0034482758620689655, 'you': 0.03103448...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'PROPN': 0.07807308970099668, 'PRON': 0.13621...</td>\n",
       "      <td>[(and,), (sureño, vida), (bald, and, brown), (...</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.320690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13722</th>\n",
       "      <td>WW III</td>\n",
       "      <td>Ruff Ryders</td>\n",
       "      <td>ruff ryders ruff ryders ryde or die volume 2 t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.419214</td>\n",
       "      <td>1</td>\n",
       "      <td>{'motherfucker': 3, 'nigga': 14, 'motherfuckin...</td>\n",
       "      <td>4.016411</td>\n",
       "      <td>[tugboats, ehh, ahhhhahahahahahaha, yess, cock...</td>\n",
       "      <td>0.419037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125546</td>\n",
       "      <td>{'i': 0.015317286652078774, 'you': 0.047045951...</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>{'PROPN': 0.08059384941675504, 'NOUN': 0.21739...</td>\n",
       "      <td>[(you,), (ryde, or), (ryde, or, die), (ryde, o...</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.303063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13723</th>\n",
       "      <td>So Many Tears</td>\n",
       "      <td>2Pac</td>\n",
       "      <td>i shall not fear no man but god though i walk ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440932</td>\n",
       "      <td>1</td>\n",
       "      <td>{'god': 6, 'nigga': 1, 'thug': 1, 'fuck': 1, '...</td>\n",
       "      <td>3.846411</td>\n",
       "      <td>[thrived, kato, hatched, paintin, disillusioned]</td>\n",
       "      <td>0.440735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069884</td>\n",
       "      <td>{'i': 0.05175292153589316, 'you': 0.0050083472...</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>{'PRON': 0.15151515151515152, 'AUX': 0.0494417...</td>\n",
       "      <td>[(i,), (so, many), (so, many, tears), (shed, s...</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.283806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13724</th>\n",
       "      <td>Teddy's Jam</td>\n",
       "      <td>Guy</td>\n",
       "      <td>attention this is a interruption stay tuned fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271949</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.649351</td>\n",
       "      <td>[interruption, teddys, ooheee, standby]</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186296</td>\n",
       "      <td>{'i': 0.025974025974025976, 'you': 0.058441558...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'NOUN': 0.2076271186440678, 'PRON': 0.2288135...</td>\n",
       "      <td>[(shake,), (shake, it), (shake, shake, it), (s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.240260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>hello hello allow me to introduce myself mysel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408432</td>\n",
       "      <td>1</td>\n",
       "      <td>{'damn': 3, 'whore': 1, 'titties': 1, 'rum': 1...</td>\n",
       "      <td>3.903821</td>\n",
       "      <td>[recklessly, stephanies, sesame, rattattap, at...</td>\n",
       "      <td>0.408432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097497</td>\n",
       "      <td>{'i': 0.03557312252964427, 'you': 0.0210803689...</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>{'INTJ': 0.02648171500630517, 'VERB': 0.163934...</td>\n",
       "      <td>[(to,), (i, dont), (girl, i, dont), (girl, i, ...</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.293808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7725 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         track_name    track_artist  \\\n",
       "6001         Love - Remastered 2010     John Lennon   \n",
       "6002     Atmosphere - 2010 Remaster    Joy Division   \n",
       "6003   While My Guitar Gently Weeps  Regina Spektor   \n",
       "6004            What You're Made Of  Arrested Youth   \n",
       "6005            No Strings Attached           SWACQ   \n",
       "...                             ...             ...   \n",
       "13721                   Sureno Vida       Brownside   \n",
       "13722                        WW III     Ruff Ryders   \n",
       "13723                 So Many Tears            2Pac   \n",
       "13724                   Teddy's Jam             Guy   \n",
       "13725                         Hello          Eminem   \n",
       "\n",
       "                                                  lyrics  track_popularity  \\\n",
       "6001   love is real real is love love is feeling feel...                50   \n",
       "6002   walk in silence dont walk away in silence see ...                50   \n",
       "6003   na i look at you all see the love there thats ...                50   \n",
       "6004   i still act like i did back in the sixth grade...                50   \n",
       "6005   come on children now were gonna have a little ...                50   \n",
       "...                                                  ...               ...   \n",
       "13721  sureño vida thats what we gonna call this moth...                 0   \n",
       "13722  ruff ryders ruff ryders ryde or die volume 2 t...                 0   \n",
       "13723  i shall not fear no man but god though i walk ...                 0   \n",
       "13724  attention this is a interruption stay tuned fo...                 0   \n",
       "13725  hello hello allow me to introduce myself mysel...                 0   \n",
       "\n",
       "       diversity  is_explicit  \\\n",
       "6001    0.317460            0   \n",
       "6002    0.646341            1   \n",
       "6003    0.370130            0   \n",
       "6004    0.121212            1   \n",
       "6005    0.869565            1   \n",
       "...          ...          ...   \n",
       "13721   0.521441            1   \n",
       "13722   0.419214            1   \n",
       "13723   0.440932            1   \n",
       "13724   0.271949            0   \n",
       "13725   0.408432            1   \n",
       "\n",
       "                                    explicit_word_counts  average_word_length  \\\n",
       "6001                                                  {}             3.746032   \n",
       "6002                                        {'naked': 1}             4.487805   \n",
       "6003                                                  {}             4.116883   \n",
       "6004      {'shit': 3, 'bitch': 3, 'hell': 9, 'fucks': 3}             3.746411   \n",
       "6005                                        {'organ': 1}             4.000000   \n",
       "...                                                  ...                  ...   \n",
       "13721  {'motherfucker': 1, 'hell': 5, 'shit': 2, 'fuc...             4.213793   \n",
       "13722  {'motherfucker': 3, 'nigga': 14, 'motherfuckin...             4.016411   \n",
       "13723  {'god': 6, 'nigga': 1, 'thug': 1, 'fuck': 1, '...             3.846411   \n",
       "13724                                                 {}             3.649351   \n",
       "13725  {'damn': 3, 'whore': 1, 'titties': 1, 'rum': 1...             3.903821   \n",
       "\n",
       "                                          uncommon_words       TTR  ...  \\\n",
       "6001                                                  []  0.317460  ...   \n",
       "6002                             [rebuilding, confronts]  0.646341  ...   \n",
       "6003                       [diverted, inverted, alerted]  0.370130  ...   \n",
       "6004   [whiny, tantrums, whiny, tantrums, whiny, tant...  0.121212  ...   \n",
       "6005                                                  []  0.863636  ...   \n",
       "...                                                  ...       ...  ...   \n",
       "13721  [qvo, malito, 1990, malito, explicando, realid...  0.520690  ...   \n",
       "13722  [tugboats, ehh, ahhhhahahahahahaha, yess, cock...  0.419037  ...   \n",
       "13723   [thrived, kato, hatched, paintin, disillusioned]  0.440735  ...   \n",
       "13724            [interruption, teddys, ooheee, standby]  0.272727  ...   \n",
       "13725  [recklessly, stephanies, sesame, rattattap, at...  0.408432  ...   \n",
       "\n",
       "       pronoun_proportion                       specific_pronoun_proportions  \\\n",
       "6001             0.063492  {'you': 0.031746031746031744, 'we': 0.01587301...   \n",
       "6002             0.048780  {'you': 0.012195121951219513, 'it': 0.01219512...   \n",
       "6003             0.162338  {'i': 0.06493506493506493, 'you': 0.0649350649...   \n",
       "6004             0.088517  {'i': 0.0430622009569378, 'you': 0.00956937799...   \n",
       "6005             0.000000                                                 {}   \n",
       "...                   ...                                                ...   \n",
       "13721            0.102916  {'i': 0.0034482758620689655, 'you': 0.03103448...   \n",
       "13722            0.125546  {'i': 0.015317286652078774, 'you': 0.047045951...   \n",
       "13723            0.069884  {'i': 0.05175292153589316, 'you': 0.0050083472...   \n",
       "13724            0.186296  {'i': 0.025974025974025976, 'you': 0.058441558...   \n",
       "13725            0.097497  {'i': 0.03557312252964427, 'you': 0.0210803689...   \n",
       "\n",
       "       prop_male_pronouns  prop_female_pronouns  prop_neutral_pronouns  \\\n",
       "6001             0.000000              0.000000               1.000000   \n",
       "6002             0.000000              0.000000               1.000000   \n",
       "6003             0.000000              0.000000               1.000000   \n",
       "6004             0.000000              0.000000               1.000000   \n",
       "6005             0.000000              0.000000               0.000000   \n",
       "...                   ...                   ...                    ...   \n",
       "13721            0.000000              0.000000               1.000000   \n",
       "13722            0.027027              0.000000               0.972973   \n",
       "13723            0.021053              0.000000               0.978947   \n",
       "13724            0.000000              0.000000               1.000000   \n",
       "13725            0.061404              0.008772               0.929825   \n",
       "\n",
       "                                           pos_frequency  \\\n",
       "6001   {'NOUN': 0.30158730158730157, 'AUX': 0.3015873...   \n",
       "6002   {'VERB': 0.19318181818181818, 'ADP': 0.1363636...   \n",
       "6003   {'PART': 0.0375, 'PRON': 0.2625, 'VERB': 0.218...   \n",
       "6004   {'PRON': 0.17647058823529413, 'ADV': 0.0565610...   \n",
       "6005   {'VERB': 0.21739130434782608, 'ADP': 0.1304347...   \n",
       "...                                                  ...   \n",
       "13721  {'PROPN': 0.07807308970099668, 'PRON': 0.13621...   \n",
       "13722  {'PROPN': 0.08059384941675504, 'NOUN': 0.21739...   \n",
       "13723  {'PRON': 0.15151515151515152, 'AUX': 0.0494417...   \n",
       "13724  {'NOUN': 0.2076271186440678, 'PRON': 0.2288135...   \n",
       "13725  {'INTJ': 0.02648171500630517, 'VERB': 0.163934...   \n",
       "\n",
       "                                                 n_grams  simile_density  \\\n",
       "6001   [(love,), (love, is), (love, love, is), (is, l...        0.000000   \n",
       "6002   [(walk,), (in, silence), (dont, walk, away), (...        0.012195   \n",
       "6003   [(i,), (my, guitar), (my, guitar, gently), (my...        0.000000   \n",
       "6004   [(i,), (oh, oh), (oh, oh, oh), (show, me, what...        0.000797   \n",
       "6005   [(on,), (come, on), (come, on, children), (com...        0.000000   \n",
       "...                                                  ...             ...   \n",
       "13721  [(and,), (sureño, vida), (bald, and, brown), (...        0.001724   \n",
       "13722  [(you,), (ryde, or), (ryde, or, die), (ryde, o...        0.001094   \n",
       "13723  [(i,), (so, many), (so, many, tears), (shed, s...        0.001669   \n",
       "13724  [(shake,), (shake, it), (shake, shake, it), (s...        0.000000   \n",
       "13725  [(to,), (i, dont), (girl, i, dont), (girl, i, ...        0.001318   \n",
       "\n",
       "       metaphor_density  alliteration_density  \n",
       "6001           0.015873              0.301587  \n",
       "6002           0.000000              0.304878  \n",
       "6003           0.006494              0.266234  \n",
       "6004           0.000797              0.183413  \n",
       "6005           0.045455              0.318182  \n",
       "...                 ...                   ...  \n",
       "13721          0.001724              0.320690  \n",
       "13722          0.001094              0.303063  \n",
       "13723          0.001669              0.283806  \n",
       "13724          0.002165              0.240260  \n",
       "13725          0.001318              0.293808  \n",
       "\n",
       "[7725 rows x 30 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpopular_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ae7905",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b12aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are getting the proportions of various named entities in the lyrics\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def calculate_named_entity_proportions(lyrics, entity_types):\n",
    "    doc = nlp(lyrics)\n",
    "    total_words = len(doc)\n",
    "    \n",
    "    named_entities = [ent for ent in doc.ents if ent.label_ in entity_types]\n",
    "    \n",
    "    named_entity_counts = Counter(ent.label_ for ent in named_entities)\n",
    "    \n",
    "    named_entity_proportions = {entity_type: count / total_words for entity_type, \n",
    "                                count in named_entity_counts.items()}\n",
    "    \n",
    "    return named_entity_proportions\n",
    "\n",
    "selected_entity_types = ['PERSON', 'ORG', 'GPE', 'EVENT', 'PRODUCT', 'WORK_OF_ART', 'MONEY', 'TIME']\n",
    "\n",
    "popular_data['named_entity_proportions'] = popular_data['lyrics'].apply(lambda lyrics: calculate_named_entity_proportions(lyrics, selected_entity_types))\n",
    "unpopular_data['named_entity_proportions'] = unpopular_data['lyrics'].apply(lambda lyrics: calculate_named_entity_proportions(lyrics, selected_entity_types))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d73ebd2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e19a9208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nNOTE: this feature proved to be too computationally demanding. \\nIn the presentation, we refer to our initial calculation for word2vec similarity, \\nwhich simply uses the whole corpus of lyrics, which is not revelant for model building here.\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "NOTE: getting this feature proved to be too computationally demanding. \n",
    "In the presentation, we refer to our initial calculation for word2vec similarity, \n",
    "which simply uses the whole corpus of lyrics, which is not revelant for model building here.\n",
    "'''\n",
    "\n",
    "\n",
    "# # Here we are adding a feature which is the lyrics' similarity to a Google News word model\n",
    "# word2vec_model = api.load(\"word2vec-google-news-300\") # Load the model\n",
    "\n",
    "# # Function to get the similarity between each set of lyrics and the model\n",
    "# def calculate_similarity(lyrics, word2vec_model):\n",
    "#     words = lyrics.split()\n",
    "#     word_vectors = []\n",
    "#     for word in words:\n",
    "#         if word in word2vec_model:\n",
    "#             word_vectors.append(word2vec_model[word])\n",
    "#     if not word_vectors:\n",
    "#         return 0.0  \n",
    "#     lyrics_vector = np.mean(word_vectors, axis=0)\n",
    "#     similarities = word2vec_model.cosine_similarities(lyrics_vector, \n",
    "#                                                       [word2vec_model[word] \\\n",
    "#                                                        for word in word2vec_model.index_to_key])\n",
    "#     return max(similarities)  \n",
    "\n",
    "# def add_similarity_column(df, word2vec_model):\n",
    "#     similarities = []\n",
    "#     for lyrics in df['lyrics']:\n",
    "#         similarity = calculate_similarity(lyrics, word2vec_model)\n",
    "#         similarities.append(similarity)\n",
    "#     df['similarity_to_word2vec'] = similarities\n",
    "\n",
    "# add_similarity_column(popular_data, word2vec_model)\n",
    "# add_similarity_column(unpopular_data, word2vec_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3860ef",
   "metadata": {},
   "source": [
    "---\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d06b1d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-29 03:47:08.944514: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, InputLayer\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfc586f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_name</th>\n",
       "      <th>track_artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>track_popularity</th>\n",
       "      <th>diversity</th>\n",
       "      <th>is_explicit</th>\n",
       "      <th>explicit_word_counts</th>\n",
       "      <th>average_word_length</th>\n",
       "      <th>uncommon_words</th>\n",
       "      <th>TTR</th>\n",
       "      <th>...</th>\n",
       "      <th>specific_pronoun_proportions</th>\n",
       "      <th>prop_male_pronouns</th>\n",
       "      <th>prop_female_pronouns</th>\n",
       "      <th>prop_neutral_pronouns</th>\n",
       "      <th>pos_frequency</th>\n",
       "      <th>n_grams</th>\n",
       "      <th>simile_density</th>\n",
       "      <th>metaphor_density</th>\n",
       "      <th>alliteration_density</th>\n",
       "      <th>named_entity_proportions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Memories</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>heres to the ones that we got cheers to the wi...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>4.455696</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.032911</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.02278481012658228, 'you': 0.0303797468...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'NOUN': 0.21318069306930693, 'ADP': 0.0866336...</td>\n",
       "      <td>[(the,), (bring, back), (memories, bring, back...</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>{'PERSON': 0.007425742574257425}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Box</td>\n",
       "      <td>Roddy Ricch</td>\n",
       "      <td>pullin out the coupe at the lot told em fuck 1...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>1</td>\n",
       "      <td>{'fuck': 48, 'damn': 24, 'sucked': 24, 'nigga'...</td>\n",
       "      <td>3.588665</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.043876</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.054844606946983544, 'you': 0.007312614...</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>{'VERB': 0.17618629173989456, 'ADP': 0.0949033...</td>\n",
       "      <td>[(the,), (the, box), (i, got, the), (pullin, o...</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.078611</td>\n",
       "      <td>{'ORG': 0.0017574692442882249, 'PERSON': 0.007...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>yeah ive been tryna call ive been on my own fo...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.045849</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.471042</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.045849</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.08494208494208494, 'you': 0.0231660231...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'INTJ': 0.0989399293286219, 'PRON': 0.2049469...</td>\n",
       "      <td>[(i,), (hey, hey), (i, said, ooh), (i, said, o...</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075290</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Circles</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>oh oh oh oh oh oh oh oh oh oh oh we couldnt tu...</td>\n",
       "      <td>98</td>\n",
       "      <td>0.061146</td>\n",
       "      <td>1</td>\n",
       "      <td>{'sex': 10}</td>\n",
       "      <td>3.613419</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.060703</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.04472843450479233, 'you': 0.0351437699...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'INTJ': 0.03343465045592705, 'PRON': 0.182370...</td>\n",
       "      <td>[(run,), (run, away), (oh, oh, oh), (run, away...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.108626</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Don't Start Now</td>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td>if you dont wanna see me did a full 180 crazy ...</td>\n",
       "      <td>97</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.634868</td>\n",
       "      <td>[]</td>\n",
       "      <td>0.030428</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.006578947368421052, 'you': 0.052631578...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'SCONJ': 0.05588235294117647, 'PRON': 0.16176...</td>\n",
       "      <td>[(dont,), (up, up), (dont, come, out), (up, do...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.057155</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13721</th>\n",
       "      <td>Sureno Vida</td>\n",
       "      <td>Brownside</td>\n",
       "      <td>sureño vida thats what we gonna call this moth...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.521441</td>\n",
       "      <td>1</td>\n",
       "      <td>{'motherfucker': 1, 'hell': 5, 'shit': 2, 'fuc...</td>\n",
       "      <td>4.213793</td>\n",
       "      <td>[qvo, malito, 1990, malito, explicando, realid...</td>\n",
       "      <td>0.520690</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.0034482758620689655, 'you': 0.03103448...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'PROPN': 0.07807308970099668, 'PRON': 0.13621...</td>\n",
       "      <td>[(and,), (sureño, vida), (bald, and, brown), (...</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>0.320690</td>\n",
       "      <td>{'PERSON': 0.0049833887043189366, 'GPE': 0.004...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13722</th>\n",
       "      <td>WW III</td>\n",
       "      <td>Ruff Ryders</td>\n",
       "      <td>ruff ryders ruff ryders ryde or die volume 2 t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.419214</td>\n",
       "      <td>1</td>\n",
       "      <td>{'motherfucker': 3, 'nigga': 14, 'motherfuckin...</td>\n",
       "      <td>4.016411</td>\n",
       "      <td>[tugboats, ehh, ahhhhahahahahahaha, yess, cock...</td>\n",
       "      <td>0.419037</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.015317286652078774, 'you': 0.047045951...</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>{'PROPN': 0.08059384941675504, 'NOUN': 0.21739...</td>\n",
       "      <td>[(you,), (ryde, or), (ryde, or, die), (ryde, o...</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.303063</td>\n",
       "      <td>{'PERSON': 0.008483563096500531, 'GPE': 0.0042...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13723</th>\n",
       "      <td>So Many Tears</td>\n",
       "      <td>2Pac</td>\n",
       "      <td>i shall not fear no man but god though i walk ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.440932</td>\n",
       "      <td>1</td>\n",
       "      <td>{'god': 6, 'nigga': 1, 'thug': 1, 'fuck': 1, '...</td>\n",
       "      <td>3.846411</td>\n",
       "      <td>[thrived, kato, hatched, paintin, disillusioned]</td>\n",
       "      <td>0.440735</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.05175292153589316, 'you': 0.0050083472...</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978947</td>\n",
       "      <td>{'PRON': 0.15151515151515152, 'AUX': 0.0494417...</td>\n",
       "      <td>[(i,), (so, many), (so, many, tears), (shed, s...</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.001669</td>\n",
       "      <td>0.283806</td>\n",
       "      <td>{'PERSON': 0.004784688995215311, 'TIME': 0.001...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13724</th>\n",
       "      <td>Teddy's Jam</td>\n",
       "      <td>Guy</td>\n",
       "      <td>attention this is a interruption stay tuned fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.271949</td>\n",
       "      <td>0</td>\n",
       "      <td>{}</td>\n",
       "      <td>3.649351</td>\n",
       "      <td>[interruption, teddys, ooheee, standby]</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.025974025974025976, 'you': 0.058441558...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'NOUN': 0.2076271186440678, 'PRON': 0.2288135...</td>\n",
       "      <td>[(shake,), (shake, it), (shake, shake, it), (s...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.240260</td>\n",
       "      <td>{'PERSON': 0.006355932203389831, 'TIME': 0.010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13725</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Eminem</td>\n",
       "      <td>hello hello allow me to introduce myself mysel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.408432</td>\n",
       "      <td>1</td>\n",
       "      <td>{'damn': 3, 'whore': 1, 'titties': 1, 'rum': 1...</td>\n",
       "      <td>3.903821</td>\n",
       "      <td>[recklessly, stephanies, sesame, rattattap, at...</td>\n",
       "      <td>0.408432</td>\n",
       "      <td>...</td>\n",
       "      <td>{'i': 0.03557312252964427, 'you': 0.0210803689...</td>\n",
       "      <td>0.061404</td>\n",
       "      <td>0.008772</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>{'INTJ': 0.02648171500630517, 'VERB': 0.163934...</td>\n",
       "      <td>[(to,), (i, dont), (girl, i, dont), (girl, i, ...</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.293808</td>\n",
       "      <td>{'PERSON': 0.0025220680958385876}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13726 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            track_name track_artist  \\\n",
       "0             Memories     Maroon 5   \n",
       "1              The Box  Roddy Ricch   \n",
       "2      Blinding Lights   The Weeknd   \n",
       "3              Circles  Post Malone   \n",
       "4      Don't Start Now     Dua Lipa   \n",
       "...                ...          ...   \n",
       "13721      Sureno Vida    Brownside   \n",
       "13722           WW III  Ruff Ryders   \n",
       "13723    So Many Tears         2Pac   \n",
       "13724      Teddy's Jam          Guy   \n",
       "13725            Hello       Eminem   \n",
       "\n",
       "                                                  lyrics  track_popularity  \\\n",
       "0      heres to the ones that we got cheers to the wi...                98   \n",
       "1      pullin out the coupe at the lot told em fuck 1...                98   \n",
       "2      yeah ive been tryna call ive been on my own fo...                98   \n",
       "3      oh oh oh oh oh oh oh oh oh oh oh we couldnt tu...                98   \n",
       "4      if you dont wanna see me did a full 180 crazy ...                97   \n",
       "...                                                  ...               ...   \n",
       "13721  sureño vida thats what we gonna call this moth...                 0   \n",
       "13722  ruff ryders ruff ryders ryde or die volume 2 t...                 0   \n",
       "13723  i shall not fear no man but god though i walk ...                 0   \n",
       "13724  attention this is a interruption stay tuned fo...                 0   \n",
       "13725  hello hello allow me to introduce myself mysel...                 0   \n",
       "\n",
       "       diversity  is_explicit  \\\n",
       "0       0.032911            0   \n",
       "1       0.043243            1   \n",
       "2       0.045849            0   \n",
       "3       0.061146            1   \n",
       "4       0.030145            0   \n",
       "...          ...          ...   \n",
       "13721   0.521441            1   \n",
       "13722   0.419214            1   \n",
       "13723   0.440932            1   \n",
       "13724   0.271949            0   \n",
       "13725   0.408432            1   \n",
       "\n",
       "                                    explicit_word_counts  average_word_length  \\\n",
       "0                                                     {}             4.455696   \n",
       "1      {'fuck': 48, 'damn': 24, 'sucked': 24, 'nigga'...             3.588665   \n",
       "2                                                     {}             3.471042   \n",
       "3                                            {'sex': 10}             3.613419   \n",
       "4                                                     {}             3.634868   \n",
       "...                                                  ...                  ...   \n",
       "13721  {'motherfucker': 1, 'hell': 5, 'shit': 2, 'fuc...             4.213793   \n",
       "13722  {'motherfucker': 3, 'nigga': 14, 'motherfuckin...             4.016411   \n",
       "13723  {'god': 6, 'nigga': 1, 'thug': 1, 'fuck': 1, '...             3.846411   \n",
       "13724                                                 {}             3.649351   \n",
       "13725  {'damn': 3, 'whore': 1, 'titties': 1, 'rum': 1...             3.903821   \n",
       "\n",
       "                                          uncommon_words       TTR  ...  \\\n",
       "0                                                     []  0.032911  ...   \n",
       "1                                                     []  0.043876  ...   \n",
       "2                                                     []  0.045849  ...   \n",
       "3                                                     []  0.060703  ...   \n",
       "4                                                     []  0.030428  ...   \n",
       "...                                                  ...       ...  ...   \n",
       "13721  [qvo, malito, 1990, malito, explicando, realid...  0.520690  ...   \n",
       "13722  [tugboats, ehh, ahhhhahahahahahaha, yess, cock...  0.419037  ...   \n",
       "13723   [thrived, kato, hatched, paintin, disillusioned]  0.440735  ...   \n",
       "13724            [interruption, teddys, ooheee, standby]  0.272727  ...   \n",
       "13725  [recklessly, stephanies, sesame, rattattap, at...  0.408432  ...   \n",
       "\n",
       "                            specific_pronoun_proportions  prop_male_pronouns  \\\n",
       "0      {'i': 0.02278481012658228, 'you': 0.0303797468...            0.000000   \n",
       "1      {'i': 0.054844606946983544, 'you': 0.007312614...            0.031746   \n",
       "2      {'i': 0.08494208494208494, 'you': 0.0231660231...            0.000000   \n",
       "3      {'i': 0.04472843450479233, 'you': 0.0351437699...            0.000000   \n",
       "4      {'i': 0.006578947368421052, 'you': 0.052631578...            0.000000   \n",
       "...                                                  ...                 ...   \n",
       "13721  {'i': 0.0034482758620689655, 'you': 0.03103448...            0.000000   \n",
       "13722  {'i': 0.015317286652078774, 'you': 0.047045951...            0.027027   \n",
       "13723  {'i': 0.05175292153589316, 'you': 0.0050083472...            0.021053   \n",
       "13724  {'i': 0.025974025974025976, 'you': 0.058441558...            0.000000   \n",
       "13725  {'i': 0.03557312252964427, 'you': 0.0210803689...            0.061404   \n",
       "\n",
       "       prop_female_pronouns  prop_neutral_pronouns  \\\n",
       "0                  0.000000               1.000000   \n",
       "1                  0.126984               0.841270   \n",
       "2                  0.000000               1.000000   \n",
       "3                  0.000000               1.000000   \n",
       "4                  0.000000               1.000000   \n",
       "...                     ...                    ...   \n",
       "13721              0.000000               1.000000   \n",
       "13722              0.000000               0.972973   \n",
       "13723              0.000000               0.978947   \n",
       "13724              0.000000               1.000000   \n",
       "13725              0.008772               0.929825   \n",
       "\n",
       "                                           pos_frequency  \\\n",
       "0      {'NOUN': 0.21318069306930693, 'ADP': 0.0866336...   \n",
       "1      {'VERB': 0.17618629173989456, 'ADP': 0.0949033...   \n",
       "2      {'INTJ': 0.0989399293286219, 'PRON': 0.2049469...   \n",
       "3      {'INTJ': 0.03343465045592705, 'PRON': 0.182370...   \n",
       "4      {'SCONJ': 0.05588235294117647, 'PRON': 0.16176...   \n",
       "...                                                  ...   \n",
       "13721  {'PROPN': 0.07807308970099668, 'PRON': 0.13621...   \n",
       "13722  {'PROPN': 0.08059384941675504, 'NOUN': 0.21739...   \n",
       "13723  {'PRON': 0.15151515151515152, 'AUX': 0.0494417...   \n",
       "13724  {'NOUN': 0.2076271186440678, 'PRON': 0.2288135...   \n",
       "13725  {'INTJ': 0.02648171500630517, 'VERB': 0.163934...   \n",
       "\n",
       "                                                 n_grams  simile_density  \\\n",
       "0      [(the,), (bring, back), (memories, bring, back...        0.000316   \n",
       "1      [(the,), (the, box), (i, got, the), (pullin, o...        0.000229   \n",
       "2      [(i,), (hey, hey), (i, said, ooh), (i, said, o...        0.000483   \n",
       "3      [(run,), (run, away), (oh, oh, oh), (run, away...        0.000000   \n",
       "4      [(dont,), (up, up), (dont, come, out), (up, do...        0.000000   \n",
       "...                                                  ...             ...   \n",
       "13721  [(and,), (sureño, vida), (bald, and, brown), (...        0.001724   \n",
       "13722  [(you,), (ryde, or), (ryde, or, die), (ryde, o...        0.001094   \n",
       "13723  [(i,), (so, many), (so, many, tears), (shed, s...        0.001669   \n",
       "13724  [(shake,), (shake, it), (shake, shake, it), (s...        0.000000   \n",
       "13725  [(to,), (i, dont), (girl, i, dont), (girl, i, ...        0.001318   \n",
       "\n",
       "       metaphor_density  alliteration_density  \\\n",
       "0              0.000316              0.056962   \n",
       "1              0.000229              0.078611   \n",
       "2              0.000000              0.075290   \n",
       "3              0.000639              0.108626   \n",
       "4              0.000411              0.057155   \n",
       "...                 ...                   ...   \n",
       "13721          0.001724              0.320690   \n",
       "13722          0.001094              0.303063   \n",
       "13723          0.001669              0.283806   \n",
       "13724          0.002165              0.240260   \n",
       "13725          0.001318              0.293808   \n",
       "\n",
       "                                named_entity_proportions  \n",
       "0                       {'PERSON': 0.007425742574257425}  \n",
       "1      {'ORG': 0.0017574692442882249, 'PERSON': 0.007...  \n",
       "2                                                     {}  \n",
       "3                                                     {}  \n",
       "4                                                     {}  \n",
       "...                                                  ...  \n",
       "13721  {'PERSON': 0.0049833887043189366, 'GPE': 0.004...  \n",
       "13722  {'PERSON': 0.008483563096500531, 'GPE': 0.0042...  \n",
       "13723  {'PERSON': 0.004784688995215311, 'TIME': 0.001...  \n",
       "13724  {'PERSON': 0.006355932203389831, 'TIME': 0.010...  \n",
       "13725                  {'PERSON': 0.0025220680958385876}  \n",
       "\n",
       "[13726 rows x 31 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.concat([popular_data, unpopular_data], ignore_index=True) # Merge the data\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3d4e34",
   "metadata": {},
   "source": [
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f293319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['track_name', 'track_artist', 'lyrics', 'track_popularity', 'diversity',\n",
       "       'is_explicit', 'explicit_word_counts', 'average_word_length',\n",
       "       'uncommon_words', 'TTR', 'repetition', 'rhyme_proportion', 'num_words',\n",
       "       'num_characters', 'num_consonants', 'num_vowels',\n",
       "       'consonant_proportion', 'vowel_proportion', 'consonants_per_word',\n",
       "       'vowels_per_word', 'pronoun_proportion', 'specific_pronoun_proportions',\n",
       "       'prop_male_pronouns', 'prop_female_pronouns', 'prop_neutral_pronouns',\n",
       "       'pos_frequency', 'n_grams', 'simile_density', 'metaphor_density',\n",
       "       'alliteration_density', 'named_entity_proportions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20174d9f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c6aa94c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "diversity                float64\n",
       "is_explicit                int64\n",
       "average_word_length      float64\n",
       "TTR                      float64\n",
       "repetition               float64\n",
       "rhyme_proportion         float64\n",
       "num_words                float64\n",
       "num_characters           float64\n",
       "num_consonants           float64\n",
       "num_vowels               float64\n",
       "consonant_proportion     float64\n",
       "vowel_proportion         float64\n",
       "consonants_per_word      float64\n",
       "vowels_per_word          float64\n",
       "pronoun_proportion       float64\n",
       "prop_male_pronouns       float64\n",
       "prop_female_pronouns     float64\n",
       "prop_neutral_pronouns    float64\n",
       "simile_density           float64\n",
       "metaphor_density         float64\n",
       "alliteration_density     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get X. Unfortunately, some features proved too complex to be able to be meaningfully incorporated into the model.\n",
    "X = merged_data.drop(columns=['track_name',\n",
    "                              'track_artist',\n",
    "                              'track_popularity', \n",
    "                              'explicit_word_counts',\n",
    "                              'lyrics',\n",
    "                              'uncommon_words', \n",
    "                              'specific_pronoun_proportions', \n",
    "                              'pos_frequency', \n",
    "                              'n_grams',\n",
    "                              'named_entity_proportions'])\n",
    "X.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfd427ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        98\n",
       "1        98\n",
       "2        98\n",
       "3        98\n",
       "4        97\n",
       "         ..\n",
       "13721     0\n",
       "13722     0\n",
       "13723     0\n",
       "13724     0\n",
       "13725     0\n",
       "Name: track_popularity, Length: 13726, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = merged_data['track_popularity']\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef32498e",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c66e26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the splits (0.2 test size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25323000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Baseline Mean Squared Error: 1154.2698470502548\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We decided that a random model is a reasonable baseline because for someone with little to no interest in or \n",
    "knowledge of music or the music industry, it would likely be very difficult for someone looking at a song's \n",
    "lyrics and characteristics of them to be able to determine the popularity score, let alone range, so their baseline\n",
    "guess would essentially be random.\n",
    "'''\n",
    "random_predictions = np.random.choice(y_train, size=len(y_test), replace=True)\n",
    "random_mse = mean_squared_error(y_test, random_predictions)\n",
    "print(\"Random Baseline Mean Squared Error:\", random_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508baa8c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfdb791e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features: Index(['diversity', 'TTR', 'repetition', 'num_words', 'num_characters',\n",
      "       'num_consonants', 'num_vowels', 'prop_female_pronouns',\n",
      "       'metaphor_density', 'alliteration_density'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# We are using k=10\n",
    "# Select the best features for use in the model\n",
    "k = 10 \n",
    "selector = SelectKBest(score_func=f_regression, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "\n",
    "selected_features = X.columns[selected_feature_indices]\n",
    "print(\"Selected Features:\", selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fadf20ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 554.0706035769863\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "# 100 estimators\n",
    "model_rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Get the train and test splits\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Fit the model\n",
    "model_rf.fit(X_train_selected, y_train)\n",
    "\n",
    "# Test the model\n",
    "y_pred = model_rf.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the model initially using MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "217dc309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 23.538704373371665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theobragstad/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "64738c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[  65   42  333]\n",
      " [   3  184  691]\n",
      " [  17  247 1164]]\n"
     ]
    }
   ],
   "source": [
    "# Define cutoffs for categories so we can look at a confusion matrix\n",
    "low_threshold = 33\n",
    "high_threshold = 66\n",
    "\n",
    "y_test_class = pd.cut(y_test, bins=[-np.inf, low_threshold, high_threshold, np.inf], labels=['low', 'medium', 'high'])\n",
    "\n",
    "y_pred_class = pd.cut(y_pred, bins=[-np.inf, low_threshold, high_threshold, np.inf], labels=['low', 'medium', 'high'])\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test_class, y_pred_class)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cd1d7f7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5235628967707541\n",
      "Recall: 0.5145666423889294\n",
      "F1 Score: 0.4615679186562359\n",
      "Accuracy: 0.5145666423889294\n"
     ]
    }
   ],
   "source": [
    "# Precision, recall, F1, accuracy\n",
    "precision = precision_score(y_test_class, y_pred_class, average='weighted')\n",
    "recall = recall_score(y_test_class, y_pred_class, average='weighted')\n",
    "f1 = f1_score(y_test_class, y_pred_class, average='weighted')\n",
    "accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd12d126",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82cd0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_lyrics_simple(lyrics):\n",
    "    lyrics = lyrics.lower()\n",
    "    lyrics = re.sub(r'[^\\w\\s]', '', lyrics)\n",
    "    lyrics = re.sub(r'\\s+', ' ', lyrics.strip())\n",
    "    \n",
    "    return lyrics\n",
    "\n",
    "\n",
    "def prop_female_pronouns(pronoun_proportions):\n",
    "    total_pronouns = sum(pronoun_proportions.values())\n",
    "    female_pronouns = sum(pronoun_proportions.get(pronoun, 0) for pronoun in ['she', 'her', 'hers', 'herself'])\n",
    "    prop_female = female_pronouns / total_pronouns if total_pronouns > 0 else 0\n",
    "    return prop_female\n",
    "\n",
    "def extract_features(lyrics):\n",
    "    features = {\n",
    "        'diversity': calculate_diversity(lyrics),\n",
    "        'TTR': calculate_ttr(lyrics),\n",
    "        'repetition': calculate_repetition(lyrics),\n",
    "        'num_words': len(lyrics.split()),\n",
    "        'num_characters': len(lyrics),\n",
    "        'num_consonants': sum(1 for c in lyrics if c.lower() in 'bcdfghjklmnpqrstvwxyz'),\n",
    "        'num_vowels': sum(1 for c in lyrics if c.lower() in 'aeiou'),\n",
    "        'prop_female_pronouns': prop_female_pronouns(calculate_pronoun_proportions(lyrics)),\n",
    "        'metaphor_density': metaphor_density(lyrics),\n",
    "        'alliteration_density': alliteration_density(lyrics)\n",
    "    }\n",
    "    return pd.DataFrame([features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b02c2e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: [50.785]\n",
      "Predicted Class: medium\n"
     ]
    }
   ],
   "source": [
    "lyrics = '''\n",
    "I am unwritten\n",
    "Can't read my mind\n",
    "I'm undefined\n",
    "I'm just beginning\n",
    "The pen's in my hand\n",
    "Ending unplanned\n",
    "Staring at the blank page before you\n",
    "Open up the dirty window\n",
    "Let the sun illuminate the words that you could not find\n",
    "Reaching for something in the distance\n",
    "So close you can almost taste it\n",
    "Release your inhibitions\n",
    "Feel the rain on your skin\n",
    "No one else can feel it for you\n",
    "Only you can let it in\n",
    "No one else, no one else\n",
    "Can speak the words on your lips\n",
    "Drench yourself in words unspoken\n",
    "Live your life with arms wide open\n",
    "Today is where your book begins\n",
    "The rest is still unwritten\n",
    "Oh, oh, oh\n",
    "I break tradition\n",
    "Sometimes my tries are outside the lines\n",
    "We've been conditioned to not make mistakes\n",
    "But I can't live that way\n",
    "Staring at the blank page before you\n",
    "Open up the dirty window\n",
    "Let the sun illuminate the words that you could not find\n",
    "Reaching for something in the distance\n",
    "So close you can almost taste it\n",
    "Release your inhibitions\n",
    "Feel the rain on your skin\n",
    "No one else can feel it for you\n",
    "Only you can let it in\n",
    "No one else, no one else\n",
    "Can speak the words on your lips\n",
    "Drench yourself in words unspoken\n",
    "Live your life with arms wide open\n",
    "Today is where your book begins\n",
    "Feel the rain on your skin\n",
    "No one else can feel it for you\n",
    "Only you can let it in\n",
    "No one else, no one else\n",
    "Can speak the words on your lips\n",
    "Drench yourself in words unspoken\n",
    "Live your life with arms wide open\n",
    "Today is where your book begins\n",
    "The rest is still unwritten\n",
    "Staring at the blank page before you\n",
    "Open up the dirty window\n",
    "Let the sun illuminate the words that you could not find\n",
    "Reaching for something in the distance\n",
    "So close you can almost taste it\n",
    "Release your inhibitions\n",
    "Feel the rain on your skin\n",
    "No one else can feel it for you\n",
    "Only you can let it in\n",
    "No one else, no one else\n",
    "Can speak the words on your lips\n",
    "Drench yourself in words unspoken\n",
    "Live your life with arms wide open\n",
    "Today is where your book begins\n",
    "Feel the rain on your skin\n",
    "No one else can feel it for you\n",
    "Only you can let it in\n",
    "No one else, no one else\n",
    "Can speak the words on your lips\n",
    "Drench yourself in words unspoken\n",
    "Live your life with arms wide open\n",
    "Today is where your book begins\n",
    "The rest is still unwritten\n",
    "The rest is still unwritten\n",
    "The rest is still unwritten\n",
    "Oh, yeah, yeah\n",
    "'''\n",
    "\n",
    "input_features = extract_features(clean_lyrics_simple(lyrics))\n",
    "predicted_output = model_rf.predict(input_features)\n",
    "\n",
    "print(\"Predicted Output:\", predicted_output)\n",
    "\n",
    "predicted_class = pd.cut(predicted_output, bins=[-np.inf, 33, 66, np.inf], labels=['low', 'medium', 'high'])\n",
    "print(\"Predicted Class:\", predicted_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a0227d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: [47.5]\n",
      "Predicted Class: medium\n"
     ]
    }
   ],
   "source": [
    "lyrics = '''\n",
    "Uh-huh\n",
    "Uh-huh\n",
    "Uh-huh\n",
    "Uh-huh\n",
    "I think I started somethin'\n",
    "I got what I wanted\n",
    "Did-didn't, I can't feel nothin', superhuman\n",
    "Even when I'm fuckin', Viagra poppin'\n",
    "Every single record, autotunin'\n",
    "Zero emotion, muted emotion\n",
    "Pitch-corrected, computed emotion, uh-huh\n",
    "I blame it on the model broad with the Hollywood smile, ow\n",
    "Stripper booty and a rack like wow\n",
    "Brain like Berkeley\n",
    "Met her at Coachella\n",
    "I went to see Jigga, she went to see Z Trip\n",
    "Perfect\n",
    "I took a seat on the ice cold lawn\n",
    "She handed me a ice blue bong, whatever\n",
    "She said she wanna be a dentist really badly\n",
    "She's in school paying for tuition doing porn in the Valley\n",
    "At least you working\n",
    "But, girl, I can't feel my face\n",
    "What are we smokin' anyway?\n",
    "She said don't let the high go to waste\n",
    "But can you taste a little taste of\n",
    "Novocaine, baby, baby\n",
    "Novocaine, baby, I want you\n",
    "Fuck me good, fuck me long, fuck me numb\n",
    "Love me now, when I'm gone love me none\n",
    "Love me none, love me none\n",
    "Numb, numb, numb, numb\n",
    "Sink full of dishes, pacing in the kitchen\n",
    "Cocaine for breakfast\n",
    "Yikes\n",
    "Bed full of women\n",
    "Flip on a tripod, little red light on\n",
    "Shooting, I'm feeling like Stanley Kubrick\n",
    "This is some visionary shit\n",
    "Been tryna film pleasure with my eyes wide shut, but it keeps on moving\n",
    "I blame it on the model broad with the Hollywood smile\n",
    "Stripper booty with a rack like wow\n",
    "I'll never forget you\n",
    "You put me on a feeling I never had, never had, never had (never)\n",
    "And ever since I've been tryna get it back\n",
    "You pick it up and put it back\n",
    "Now I'm something like the chemist on campus\n",
    "But there's no drug around\n",
    "Quite like what I found in you, you\n",
    "I still can't feel my face\n",
    "What am I smokin' anyway?\n",
    "She said don't let the high go to waste\n",
    "But can you taste a little taste of?\n",
    "Novocaine, baby, baby\n",
    "Novocaine, baby, I want you\n",
    "Fuck me good, fuck me long, fuck me numb\n",
    "Love me now, when I'm gone, love me none\n",
    "Love me none, love me none\n",
    "Numb, numb, numb, numb\n",
    "Novocaine, Novocaine, Novocaine, Novocaine, Novocaine (oh, oh, oh)\n",
    "Numb the pain, numb the pain, numb the pain, numb the pain, numb the pain (yeah)\n",
    "Novocaine, Novocaine, Novocaine, Novocaine, Novocaine (oh, ho)\n",
    "For the pain, for the pain (ooh, huh)\n",
    "Novocaine, Novocaine\n",
    "Oh-huh, oh-huh, ho-huh\n",
    "Oh-huh, oh-ho, ho-ho-huh\n",
    "Oh-huh, oh-huh, ho-huh\n",
    "Oh-huh, oh-ho, ho-ho-huh\n",
    "Pretty girls involved with me\n",
    "Makin' pretty love to me, pretty, pity, pity\n",
    "All the pretty girls involved with me\n",
    "Makin' pretty love to me, pretty, pity, pity\n",
    "I can't feel a thing\n",
    "I can't feel, can't feel a thing\n",
    "Can't feel a thing, can't feel, feel, feel, feel her\n",
    "I can't feel, feel her\n",
    "Novocaine, Novocaine, Novocaine\n",
    "I can't feel, feel her\n",
    "Novocaine for the pain, for the pain\n",
    "I can't, can't feel, feel her, feel her\n",
    "Novocaine, Novocaine, cane, cane, cane\n",
    "'''\n",
    "\n",
    "input_features = extract_features(clean_lyrics_simple(lyrics))\n",
    "predicted_output = model_rf.predict(input_features)\n",
    "\n",
    "print(\"Predicted Output:\", predicted_output)\n",
    "\n",
    "predicted_class = pd.cut(predicted_output, bins=[-np.inf, 33, 66, np.inf], labels=['low', 'medium', 'high'])\n",
    "print(\"Predicted Class:\", predicted_class[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "553be0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Output: [32.60068182]\n",
      "Predicted Class: low\n"
     ]
    }
   ],
   "source": [
    "lyrics = '''\n",
    "I went with you up to the place you grew up\n",
    "And we spent a week in the cold\n",
    "Just long enough to Walden it with you\n",
    "Any longer, it would've got old\n",
    "Singin' \"Ace of Spades\" when Lemmy died\n",
    "But nothing's changed, L.A.'s alright\n",
    "I'm sleepin' in my bed again\n",
    "And gettin' in my head and then\n",
    "Walk around the reservoir\n",
    "You\n",
    "You must've been lookin' for me\n",
    "Sendin' smoke signals\n",
    "Pelicans circling\n",
    "Burnin' trash out on the beach\n",
    "One of your eyes is always half-shut\n",
    "Somethin' happened when you were a kid\n",
    "I didn't know you then and I'll never understand\n",
    "Why it feels like I did\n",
    "\"How Soon Is Now\" in an eighties sedan\n",
    "You slept inside of it because your dad\n",
    "Lived in a campground in the back of a van\n",
    "You said that song'll creep you out until you're dead\n",
    "And you\n",
    "Must've been lookin' for me\n",
    "Sendin' smoke signals\n",
    "Pelicans circling\n",
    "Burnin' trash out on the beach\n",
    "I wanna live at the Holiday Inn\n",
    "Where somebody else makes the bed\n",
    "We'll watch TV while the lights on the street\n",
    "Put all the stars to death\n",
    "It's been on my mind since Bowie died\n",
    "Just checking out to hide from life\n",
    "And all of our problems, I'm gonna solve 'em\n",
    "With you ridin' shotgun\n",
    "Speeding 'cause fuck the cops\n",
    "And you\n",
    "You must've been lookin' for me\n",
    "Sendin' smoke signals\n",
    "Pelicans circling\n",
    "Burnin' trash out on the beach\n",
    "Mm-mm\n",
    "I buried a hatchet, it's comin' up lavender\n",
    "The future's unwritten, the past is a corridor\n",
    "I'm at the exit, lookin' back through the hall\n",
    "You are anonymous, I am a concrete wall\n",
    "'''\n",
    "\n",
    "input_features = extract_features(clean_lyrics_simple(lyrics))\n",
    "predicted_output = model_rf.predict(input_features)\n",
    "\n",
    "print(\"Predicted Output:\", predicted_output)\n",
    "\n",
    "predicted_class = pd.cut(predicted_output, bins=[-np.inf, 33, 66, np.inf], labels=['low', 'medium', 'high'])\n",
    "print(\"Predicted Class:\", predicted_class[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed5c8f8",
   "metadata": {},
   "source": [
    "---\n",
    "## Other metrics and figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a672a280",
   "metadata": {},
   "source": [
    "### Please see the supplementary notebook, Song Lyrics and Commercial Performance Task - Supplementary Code for code that was not directly used for the model but rather for additional analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c63bef8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
